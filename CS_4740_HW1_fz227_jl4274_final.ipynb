{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNdFlbLJoUXM"
   },
   "source": [
    "# Homework 1: Named Entity Recognition (NER) with Sequence Labeling Models\n",
    "## CS4740/5740 Fall 2022\n",
    "\n",
    "### Milestone Submission Due: **September 15, 2022 (11:59 PM)** \n",
    "\n",
    "### Project Submission Due: **September 27, 2022 (11:59 PM)**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "871f2XhgtoYX"
   },
   "source": [
    "**Names:** Fengyue(Lisa) Zhao, Jiaqi Liang\n",
    "\n",
    "**Netids:** fz227, jl4274\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Editing your version of this notebook:** One partner should make a copy of this notebook and share it with your partner.  **However**, because of synchronization issues (even though Colab works with Google Drive), changes made in this notebook at the same time from different computers/browser windows may not save. We will go so far as to recommend that you close the tab with this notebook when you are not working on it so your partner doesn't face sync issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN0nBtOzb5u7"
   },
   "source": [
    "**Collaboration policy:** please be sure to check the collaboration policy on the [course website](https://courses.cs.cornell.edu/cs4740/2022fa/)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xY4p6eJmPPY4"
   },
   "source": [
    "> Assignment authors & testers: CS 4740/5740 professors and TAs from this and previous semesters, Chenxin Fang, Meghana Srivastava, Khonzoda Umarova, as well as Ruizhe Wang, Han Xia, and Heather Zhang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iguUiw0mor52"
   },
   "source": [
    "# **Introduction**\n",
    "---\n",
    "\n",
    "In this project, you will tackle the **Named Entity Recognition** task: you'll implement models that identify named entities in text and tag them with the appropriate label. A primer on this task is provided further on.  We will treat this as a **sequence-tagging task**: for each token in the input text, assign one of the following 5 entity labels -- **ORG** (Organization), **PER** (Person), **LOC** (Location), **MISC** (Miscellaneous), and **O** (Not Named Entity) -- as well as a BIO-format prefix **B-** (token is the *beginning* of a named entity) or **I-** (token is *inside* a named entity). Overall, this yields 9 different labels: **B-ORG, I-ORG, B-PER, I-PER, B-LOC, I-LOC, B-MISC, I-MISC** and **O**.\n",
    "\n",
    "For this project, you will implement two sequence labeling approaches:\n",
    "- Model 1 : a Hidden Markov Model (HMM)\n",
    "- Model 2 : a Maximum Entropy Markov Model (MEMM)/Logistic Regression classifier (also known as a MaxEnt classifier). Feature engineering is strongly suggested for this model!\n",
    "\n",
    "A key component of both models is implementation of the Viterbi algorithm, which we will use to find the most likely tag sequence to assign to an input text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mib4pTXj3hir"
   },
   "source": [
    "## **Logistics**\n",
    "\n",
    "---\n",
    "\n",
    "- You are **strongly encouraged** to work in **groups of 2 students**. Students in the same group will get the same grade. Thus, you should make sure that everyone in your group contributes to the project. \n",
    "- **Do not form teams of two on Kaggle** (You *will* form teams on a different platform; details TBA) because submitting separately gives you more tries, which is useful when experimenting with different models.\n",
    "- A part of your submission would involve uploading your notebook (details would be provided soon!). So, please enter all code and answer all the questions in this colab notebook.\n",
    "- In this assignment you are asked to make two submissions:\n",
    "  1. Intermediate **milestone submission due on 9/15/22 (11:59 PM)**. For this, please 1) have your teams formed (mechanism TBA) and  2) submit predictions of your first model (HMM) on Kaggle. This means that you should aim to complete Part 1 and Part 2 of the assignment by this milestone. Points will be awarded for meeting the milestone deadline, but we will only grade for completion, not correctness. \n",
    "  2. The **final homework submission due on 9/27/22 (11:59 PM)**. (details TBA)\n",
    "- Please be sure to consult the [list](https://docs.google.com/document/d/1-QmpkZYJDCM4gQQ9sZW2EwD5ltYy1CFjlJTbhD0Be-A/edit?usp=sharing) of banned packages/libraries before you start implementing your models. Note that this list may get updated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2z7TIHV3kCH"
   },
   "source": [
    "## **Advice**\n",
    "\n",
    "---\n",
    "\n",
    "1. Please read through the entire notebook before you start coding. That might inform your code structure.\n",
    "2. An assignment outline and grading breakdown (subject to minor adjustments) is found below; please consult it.\n",
    "3. The project is somewhat open ended. We will ask you to implement the models, but in some cases precise data structures and so on can be chosen by you. However, to integrate with Kaggle, you will need to submit Kaggle predictions using the given evaluation code (more instructions later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyokCzP2Zqqx"
   },
   "source": [
    "<a name=\"outline\"></a>\n",
    "## **Assignment outline and grading breakdown**\n",
    "- [Part 1](#part1)\n",
    "  - [Q1](#q1) [10 pts]\n",
    "- [Part 2](#part2)\n",
    "  - [Unknown Word Handling](#unknowns_handling) [15 pts]\n",
    "  - [HMM Implementation](#hmm_implementation) [20 pts]\n",
    "  - [Viterbi Implementation](#viterbi_implementation) [20 pts]\n",
    "  - [Validation](#validation_data) [3 pts]\n",
    "  - [Q2.1](#q2.1) [5 pts]\n",
    "  - [Q2.2](#q2.2) [5 pts]\n",
    "  - [Q2.3](#q2.3) [5 pts]\n",
    "  - [Q2.4](#q2.4) [5 pts]\n",
    "- [Part 3](#part3)\n",
    "  - [Features](#features) [35 pts]\n",
    "  - [MEMM Implementation](#memm_implementation) [25 pts]\n",
    "  - [Q3.1](#q3.1) [5 pts]\n",
    "  - [Q3.2](#q3.2) [5 pts]\n",
    "  - [Q3.3](#q3.3) [5 pts]\n",
    "  - [Q3.4](#q3.4) [5 pts]\n",
    "- [Part 4](#part4)\n",
    "  - [Q4.1](#q4.1) [7 pts]\n",
    "  - [Q4.2](#q4.2) [7 pts]\n",
    "  - [Q4.3](#q4.3) [7 pts]\n",
    "- [Part 5](#part5)\n",
    "  - [Q5](#q5)\n",
    "\n",
    "\n",
    "Meeting the milestone deadline [10 pts];\n",
    "\n",
    "Outperforming our baseline on Kaggle [15 pts];\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBsjyfPu5V4t"
   },
   "source": [
    "## **Named Entity Recognition: Review**\n",
    "\n",
    "---\n",
    "\n",
    "NER refers to the information extraction technique of identifying and categorizing key information about entities within textual data. NER is important for:\n",
    "  - Detecting entities in search engines and voice assistants for more relavent search results.\n",
    "  - Automatically parsing resumes.\n",
    "  - ...and much more!\n",
    "\n",
    "In our dataset named entity tags are formatted in BIO/IOB format. With this format, entity tags get a prefix. Prefix \"B-\" is added to the first word/token of the entity name. All following tokens that are part of the same entity name would get prefix \"I-\". \n",
    "\n",
    "Here is an example sentence: \"ZIFA\n",
    "said\n",
    "Renate\n",
    "Geotschel\n",
    "of\n",
    "Austria\n",
    "won the women's World Cup  downhill race in Germany.\"\n",
    "Entity \"Renate Goetschl\" gets \"Renate\" (B-PER) and \"Goestchl\" (I-PER). Similarly, for \"World Cup\" we'd have \"World\" (B-MISC) and \"Cup\" (I-MISC). If an entity only has one token, then its entity tag would still have prefix \"B-\". \"O\" is used to denote tokens that are not part of any named entity. Thus, from the example above, we'd have:\n",
    "\n",
    "```\"ZIFA\" B-ORG```\n",
    "\n",
    " ```\"said\" O```\n",
    "\n",
    " ```\"Renate\" B-PER```\n",
    "\n",
    " ```\"Goetschl\" I-PER```\n",
    "\n",
    " ```\"of\" O```\n",
    "\n",
    " ```\"Austria\" B-LOC```\n",
    "\n",
    " ```\"won\" O```\n",
    "\n",
    " ```\"the\" O```\n",
    "\n",
    " ```\"women's\" O```\n",
    "\n",
    " ```\"World\" B-MISC```\n",
    "\n",
    " ```\"Cup\" I-MISC```\n",
    "\n",
    " ```\"downhill\" O```\n",
    "\n",
    " ```\"race\" O```\n",
    "\n",
    " ```\"in\" O```\n",
    "\n",
    " ```\"Germany\" B-LOC```\n",
    "\n",
    "\n",
    "Although NER is predominantly handled by deep learning approaches, for now let's use HMMs and MEMMs. \n",
    "\n",
    "\n",
    "To read more on NER, we refer to any of the following sources:\n",
    "1. Medium post [1](https://umagunturi789.medium.com/everything-you-need-to-know-about-named-entity-recognition-2a136f38c08f) and [2](https://medium.com/mysuperai/what-is-named-entity-recognition-ner-and-how-can-i-use-it-2b68cf6f545d).\n",
    "2. Try out [this](https://demo.allennlp.org/named-entity-recognition/named-entity-recognition) AlllenNLP demo! Please note that this demo uses a slightly different format of NER tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSFfegs8LKY8"
   },
   "source": [
    "## **Evaluation: Entity Level Mean F1**\n",
    "\n",
    "---\n",
    "\n",
    "The standard evaluation measures to report for NER are recall, precision, and F1 score\n",
    "(also called F-measure) evaluated at the **named entity level** (not at the token level). The code for this has been provided later under the validation section under Part 2. Please use this code when evaluating your models. \n",
    "\n",
    "\n",
    "If P and T are the sets of predicted and true *named entity spans*, respectively, (e.g, the five named entity spans in the above example are \"Zifa\", \"Renate Goetschl\", \"Austria\", \"World Cup\", and \"Germany\") then\n",
    "\n",
    "####<center>Precision = $\\frac{|\\text{P}\\;\\cap\\;\\text{T}|}{|\\text{P}|}$ and Recall = $\\frac{|\\text{P}\\;\\cap\\;\\text{T}|}{|\\text{T}|}$.</center><br/>\n",
    "\n",
    "\n",
    "####<center>F1 = $\\frac{2 * \\text{Precision} * \\text{Recall}}{\\text{Precision} + \\text{Recall}}$. </center><br/>\n",
    "\n",
    "For each type of named entity, e.g. *LOC*ation, *MISC*ellaneous, *ORG*anization and *PER*son, we calculate the F1 score as shown above, and take the mean of all these F1 scores to get the **Entity Level Mean F1** score for the test set. If $N$ is the total number of labels (i.e., named entity types), then\n",
    "\n",
    "####<center>Entity Level Mean F1 = $\\frac{\\sum_{i = 1}^{N} \\text{F1}_{{label}_i}}{N}$. </center>\n",
    "\n",
    "More details under the validation section in Part 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iP63fHj5saG"
   },
   "source": [
    "<a name=\"part1\"></a>\n",
    "# **Part 1: Dataset**\n",
    "[[^^^]](#outline) \n",
    "\n",
    "Our data is a modified version of the WikiNEuRal ([ Tedeschi et al.](https://aclanthology.org/2021.findings-emnlp.215.pdf)) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pljkH2ow5U9x"
   },
   "source": [
    "Load the dataset as follows:\n",
    "  1. Obtain the data from Data tab of the [Kaggle competition](https://www.kaggle.com/t/200697e4726f448986930dd4e823e957).\n",
    "  2. Unzip the data. Put it into your Google Drive, run the cells below to mount it to Colab:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yepivWZCJD6n",
    "outputId": "bde04111-88c6-45b2-bfc1-27cbb4dfca1b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install geotext\n",
    "# !pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "mIf2wJqLzdm5"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from geotext import GeoText\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3dQChuccqfN",
    "outputId": "f6d4dc1b-03fc-425b-edcc-223cea1a28dc"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "uFXI7NRHn1Cc"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# TODO: please change the line below with your drive organization\n",
    "path = os.path.join(os.getcwd(),\"cs-4740-fa22-hw1-named-entity-recognition\")\n",
    "\n",
    "with open(os.path.join(path,'train.json'), 'r') as f:\n",
    "     train = json.loads(f.read())\n",
    "\n",
    "with open(os.path.join(path,'val.json'), 'r') as f:\n",
    "     val = json.loads(f.read())\n",
    "\n",
    "with open(os.path.join(path,'test.json'), 'r') as f:\n",
    "     test = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfjKFeE_7T7C"
   },
   "source": [
    "Here's a few things to note about the dataset above:\n",
    "1. We have loaded 3 `.json` files: for training, validation, and testing.\n",
    "2. The train and validation files contain the following 3 fields (each is a nested list): \n",
    "  - **'text'** - actual input tokens\n",
    "  - **'NER'** - the token-level entity tag \n",
    "  - **'index'** - index of the token in the dataset\n",
    "3. The test data only has **'text'**, and **'index'** fields. You will need to submit your prediction of the **'NER'** tag to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cradDk-37G8L"
   },
   "source": [
    "\n",
    "### **Q1: Initial Data Observations**\n",
    "\n",
    "In the space below please add your code for dataset explorations for Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvvRSlhb6sAR",
    "outputId": "65a83747-c7ee-459d-e5ba-204168441245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document length of training data is  7000\n",
      "The document length of validation data is  400\n",
      "The document length of testing data is  400\n",
      "The dataset size of training data is  166394\n",
      "The dataset size of validation data is  9344\n",
      "The dataset size of testing data is  8864\n"
     ]
    }
   ],
   "source": [
    "## add your code here\n",
    "print(\"The document length of training data is \", len(train['text']))\n",
    "print(\"The document length of validation data is \", len(val['text']))\n",
    "print(\"The document length of testing data is \", len(test['text']))\n",
    "\n",
    "\n",
    "def tokenSize(corpus):\n",
    "    if type(corpus) == list:\n",
    "        return sum(tokenSize(subcorpus) for subcorpus in corpus)\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "print(\"The dataset size of training data is \", tokenSize(train['text']))\n",
    "print(\"The dataset size of validation data is \", tokenSize(val['text']))\n",
    "print(\"The dataset size of testing data is \", tokenSize(test['text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CyYmQa4LwdyG",
    "outputId": "e4f34377-c872-4664-f34c-9fcc0ebb62e6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'B-LOC': 4060, 'B-PER': 3016, 'B-MISC': 2815, 'I-MISC': 2566, 'I-PER': 2217, 'B-ORG': 1725, 'I-LOC': 1451, 'I-ORG': 1431})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'B-LOC': 225, 'B-PER': 192, 'I-MISC': 156, 'I-PER': 153, 'B-MISC': 148, 'I-LOC': 111, 'B-ORG': 95, 'I-ORG': 87})\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "allNER = [item for subNER in train['NER'] for item in subNER]\n",
    "\n",
    "\n",
    "NERs, counts = zip(*Counter(allNER).items())\n",
    "\n",
    "indexes = np.arange(len(NERs))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, counts, width)\n",
    "plt.xticks(indexes + width * 0.5, NERs)\n",
    "plt.title('NER distribution in training data')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "countNER = Counter(allNER)\n",
    "del countNER['O']\n",
    "print(countNER)\n",
    "NERs, counts = zip(*countNER.items())\n",
    "\n",
    "indexes = np.arange(len(NERs))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, counts, width)\n",
    "plt.xticks(indexes + width * 0.5, NERs)\n",
    "plt.title(\"NER distribution without 'O' in training data\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "allNER = [item for subNER in val['NER'] for item in subNER]\n",
    "\n",
    "\n",
    "NERs, counts = zip(*Counter(allNER).items())\n",
    "\n",
    "indexes = np.arange(len(NERs))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, counts, width)\n",
    "plt.xticks(indexes + width * 0.5, NERs)\n",
    "plt.title('NER distribution in validation data')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "countNER = Counter(allNER)\n",
    "del countNER['O']\n",
    "print(countNER)\n",
    "NERs, counts = zip(*countNER.items())\n",
    "\n",
    "indexes = np.arange(len(NERs))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, counts, width)\n",
    "plt.xticks(indexes + width * 0.5, NERs)\n",
    "plt.title(\"NER distribution without 'O' in validation data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DebFVD7kyN01",
    "outputId": "806afd28-2e13-4923-b1d0-eda48e859a98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every aspect of life was regulated to some degree by the party , and the will of its founding-president , [B-PER]Mobutu[I-PER]Sese[I-PER]Seko. \n"
     ]
    }
   ],
   "source": [
    "text_try = train['text'][1]\n",
    "ner_try = train['NER'][1]\n",
    "words=str()\n",
    "for w in range(len(text_try)):\n",
    "    if ner_try[w] == \"O\":\n",
    "        words=words+str(text_try[w])+str(\" \")\n",
    "    else:\n",
    "        words=words+str('[')+str(ner_try[w])+str(']')+str(text_try[w])\n",
    "\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO7go9ivDusU"
   },
   "source": [
    "<a name=\"q1\"></a>\n",
    "[[^^^]](#outline) \n",
    "\n",
    "What are your initial observations after you explore the dataset?  Provide some quantitative data exploration. Assess dataset size, document lengths and the token-level NER class distribution, and the entity-level NER class distribution (skipping the 'O' label for the latter). Give some examples of sentences with their named entities bracketed, e.g. [[B-LOC Romania] state budget soars in June .] and [[B-ORG Zifa] said [B-PER Renate] [I-PER Goetschl] of [B-LOC Austria]...]. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVbqyFYq1tOy"
   },
   "source": [
    "The size of training data is  7000 <br />\n",
    "The size of validation data is  400<br />\n",
    "The size of testing data is  400<br />\n",
    "The dataset size of training data is  166394<br />\n",
    "The dataset size of validation data is  9344<br />\n",
    "The dataset size of testing data is  8864<br />\n",
    "\n",
    "<br />\n",
    "\n",
    "After plotting the histogram of token-level NER class, we found that the label 'O' is the most common label, unsurprisingly. So we ignored the 'O' label for now and looked at the entity-level NER class distribution for both the training data and validation data. We found that for both dataset, 'B-LOC' is the most common label and 'I-ORG'is the least common label. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37hVRaHczftR"
   },
   "source": [
    "Here is one example of sentences: <br>\n",
    "Every aspect of life was regulated to some degree by the party,and the will of its founding-president, [B-PER Mobutu]  [I-PER Sese]  [I-PER Seko]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NYvfchqqBf6"
   },
   "source": [
    "<a name=\"part2\"></a>\n",
    "# **Part 2: Hidden Markov Model**\n",
    "[[^^^]](#outline) \n",
    "---\n",
    "In this part of the assignment, you will:\n",
    "1. Implement code for counting and smoothing of labels and words, as well as unkown word handing, as necessary to support the Viterbi algorithm. \n",
    "2. Build a Hidden Markov Model in accordance with the provided function headers. **You may NOT change the function specifications.** Please ensure that your code is clear, concise, and, most important of all, modular. This means you should break your implementation down into smaller functions or write it within a class. Please compute all probabilities in natural log when building the HMM.\n",
    "3. Implement the **Viterbi algorithm**, that can be used to infer token-level labels (identifying the appropriate named entity) for an input document. This process is commonly referred to as **decoding**. Bigram-based Viterbi is $ \\mathcal{O}(sm^2)$ where *s* is the length of the sentence and *m* is the number of tags. Your implementation should have similar efficiency. The code for this can be used later on for the MEMM too.\n",
    "\n",
    "### References\n",
    "You may find chapters [3](https://web.stanford.edu/~jurafsky/slp3/3.pdf) and [8](https://web.stanford.edu/~jurafsky/slp3/8.pdf) of Jurafsky and Martin book useful. In particular, section 3.4.1 covers ways to handle unknown words, and section 3.5 goes over smoothing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jUVJwSaE1tI"
   },
   "source": [
    "<a name=\"unknowns_handling\"></a>\n",
    "## **Unknown Word Handling**\n",
    "[[^^^]](#outline) \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "44Bja4eQEMJR"
   },
   "outputs": [],
   "source": [
    "def unknown_word_handling(tokens, percent):\n",
    "    #tokens = train['text']\n",
    "    allTokens = [item for subitem in tokens for item in subitem]\n",
    "    TOKENs, TOKENcounts = zip(*Counter(allTokens).items())\n",
    "    TOKENs = list(TOKENs)\n",
    "    TOKENcounts = list(TOKENcounts)\n",
    "    dict_tokens = dict(zip(TOKENs, TOKENcounts))\n",
    "    dict_tokens = sorted(dict_tokens.items(), key = lambda item:item[1])\n",
    "    #print(sorted(dict_tokens.items(), key = lambda item:item[1]))\n",
    "    percentage = int(len(TOKENs)*percent)\n",
    "    dict_tokens_new= dict_tokens[0:percentage]\n",
    "    #print(dict_tokens_new)\n",
    "    unks=[]\n",
    "    for item in dict_tokens_new:\n",
    "        unks.append(item[0])\n",
    "    #print(unks)\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            if tokens[i][j] in unks:\n",
    "                tokens[i][j] = '<unk>'\n",
    "\n",
    "    train_text_new = tokens\n",
    "    return train_text_new\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWq2c6cxFQvq",
    "outputId": "8319933d-8b68-4de7-8464-3f8d69eeb0a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2482"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_new = unknown_word_handling(train['text'],0.1)\n",
    "len([token for sentence in train_text_new for token in sentence if token =='<unk>'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLuTFUV5FA3m"
   },
   "source": [
    "<a name=\"hmm_implementation\"></a>\n",
    "## **HMM Implementation**\n",
    "[[^^^]](#outline) \n",
    "---\n",
    "\n",
    "In the skeleton code below, we have broken down the HMM into its three components: the transition matrix, the emission matrix, and the start state probabilities. We suggest you implement them separately and then use them to build the HMM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "NBJgSrRtFZuG"
   },
   "outputs": [],
   "source": [
    "# Returns the transition probabilities.\n",
    "def build_transition_matrix(labels, k=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a dictionary that has tuples of every label bigram as keys, and\n",
    "    the associated value being the respective transition probabilities (in \n",
    "    natural log).\n",
    "\n",
    "    Eg. {(\"O\", \"B-ORG\"): -9.98690147425591, \n",
    "         (\"B-LOC\", \"I-LOC\"): -3.69537214,\n",
    "         ...,\n",
    "         ...,\n",
    "        }\n",
    "    \n",
    "    :parameter labels: A list where each element represents a sentence, \n",
    "    and each sentence is a list of NER labels for each of its tokens. (Eg. \n",
    "    [['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], [...], ...])\n",
    "    :type labels: List[List[String]]\n",
    "    :parameter k: an optional parameter for smoothing\n",
    "    :type k: int\n",
    "    \"\"\"\n",
    "    \n",
    "    #get types and counts of NERs\n",
    "    allNER = [item for subNER in labels for item in subNER]\n",
    "    from collections import Counter\n",
    "    NERs, NERcounts = zip(*Counter(allNER).items())\n",
    "    #get different sequences of NERs\n",
    "    ner=list(NERs)\n",
    "    ner.append('[end]')\n",
    "    ner_count=list(NERcounts)\n",
    "    seq=[]\n",
    "    N=[]\n",
    "    for n in range(0,len(ner)-1):\n",
    "        for i in range(0,len(ner)):\n",
    "            label=(ner[n],ner[i])\n",
    "            seq.append(label)\n",
    "            N.append(ner_count[n])\n",
    "\n",
    "    #count of each sequence \n",
    "    count=[]\n",
    "    for comb in seq:\n",
    "        sentence_count=0\n",
    "        if list(comb)[1] == '[end]': \n",
    "            for entity in labels:\n",
    "                if entity[-1] == list(comb)[0]:\n",
    "                    sentence_count=sentence_count+1\n",
    "            count.append(sentence_count)\n",
    "        else:\n",
    "            for entity in labels:\n",
    "                for i in range(len(entity)-1):\n",
    "                    if list(comb) == entity[i:i+2]:\n",
    "                        sentence_count=sentence_count+1\n",
    "            count.append(sentence_count) \n",
    "\n",
    "    #calculate probabilities\n",
    "    prob_trans = []\n",
    "    for a in range(0,len(seq)):\n",
    "    #smoothing here add k\n",
    "        problog=np.log((count[a]+k)/(N[a]+k*(len(ner))))\n",
    "        prob_trans.append(problog)\n",
    "    #output dictionary\n",
    "    transition = {}\n",
    "    for b in range(0,len(seq)):\n",
    "        key=seq[b]\n",
    "        transition[key]=prob_trans[b]\n",
    "  \n",
    "    return(transition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "4CjBY3y1VOms"
   },
   "outputs": [],
   "source": [
    "#build_transition_matrix(labels=train['NER'],k=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "gRt-pjh4FvZ2"
   },
   "outputs": [],
   "source": [
    "# Returns the emission probabilities.\n",
    "def build_emission_matrix(tokens, labels, k=0):\n",
    "    \"\"\"\n",
    "    Returns a dictionary that has label-token tuples as keys, and emission \n",
    "    probabilities (in natural log) for each respective label-token pair as values.  \n",
    "\n",
    "    Eg. {(\"O\", \"Because\"): -10.133904545421267, \n",
    "         (\"I-PER\", \"Markov\"): -7.428569227340841,\n",
    "         ...,\n",
    "         ...,\n",
    "        }\n",
    "    \n",
    "    :parameter tokens: A list where each element represents a sentence, \n",
    "    and each sentence is a list of its tokens. (Eg. [['The', 'most', \n",
    "    'significant', 'damage', 'was', 'on', 'Tortola', '.'], [...], ...])\n",
    "    :type tokens: List[List[String]]\n",
    "    :parameter labels: A list where each element represents a sentence, \n",
    "    and each sentence is a list of NER labels for each of its tokens. (Eg. \n",
    "    [['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], [...], ...])\n",
    "    :type labels: List[List[String]]\n",
    "    :parameter k: an optional parameter for smoothing\n",
    "    :type k: int\n",
    "    \"\"\"\n",
    "    emission = defaultdict(float)\n",
    "    allNERs = [item for subitem in labels for item in subitem]\n",
    "    uni_NERs = list(set(allNERs))\n",
    "    allTokens = [item for subitem in tokens for item in subitem]\n",
    "    uni_tokens = list(set(allTokens))\n",
    "    V = len(uni_tokens)\n",
    "    #print(len(allNERs)==len(allTokens)) # work\n",
    "    numNER = dict(Counter(allNERs).items())\n",
    "    \n",
    "    count = defaultdict(int)\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            entry = (labels[i][j],tokens[i][j])\n",
    "            count[entry] = count[entry] + 1\n",
    "    \n",
    "    #print(count) # work\n",
    "    \n",
    "    for token in uni_tokens:\n",
    "        for ner in uni_NERs:\n",
    "            entry = (ner, token)\n",
    "            #print(entry)\n",
    "            if entry in count.keys():\n",
    "                #print('yes!!')\n",
    "                prob = np.log((count[entry] + k)/(numNER[ner]+k*V))\n",
    "            else:\n",
    "                #print('smoothing!!')\n",
    "                prob = np.log(k/(numNER[ner]+k*V))\n",
    "            emission[entry] = prob\n",
    "            \n",
    "    emission[('[end]','<end>')] = np.log(1)\n",
    "\n",
    "    \n",
    "    return emission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vERzXpoU2vM9",
    "outputId": "454f8489-f28b-4394-9b81-67a488be5e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {('a', 'earth'): -1.9459101490553135,\n",
       "             ('c', 'earth'): -1.791759469228055,\n",
       "             ('b', 'earth'): -1.252762968495368,\n",
       "             ('a', 'the'): -1.252762968495368,\n",
       "             ('c', 'the'): -1.791759469228055,\n",
       "             ('b', 'the'): -1.9459101490553135,\n",
       "             ('a', 'most'): -1.9459101490553135,\n",
       "             ('c', 'most'): -1.791759469228055,\n",
       "             ('b', 'most'): -1.252762968495368,\n",
       "             ('a', 'on'): -1.252762968495368,\n",
       "             ('c', 'on'): -1.791759469228055,\n",
       "             ('b', 'on'): -1.9459101490553135,\n",
       "             ('a', 'damage'): -1.9459101490553135,\n",
       "             ('c', 'damage'): -1.0986122886681098,\n",
       "             ('b', 'damage'): -1.9459101490553135,\n",
       "             ('[end]', '<end>'): 0.0})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build_emission_matrix([['the','most'],['damage','on','earth']], [['a','b'],['c','a','b']], k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "eh4QOTOq0IAc"
   },
   "outputs": [],
   "source": [
    "#build_emission_matrix(train['text'], train['NER'], k=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "VTN9B6k0HK77"
   },
   "outputs": [],
   "source": [
    "# Returns the starting state probabilities.\n",
    "def get_start_state_probs(labels, k=0):\n",
    "    \"\"\"\n",
    "    Returns a dictionary that has labels for keys, and each respective state \n",
    "    probabilities (in natural log) for values.  \n",
    "\n",
    "    Eg. {\"O\": -10.133904545421267, \n",
    "         \"I-PER\": -7.428569227340841,\n",
    "         ...,\n",
    "         ...,\n",
    "        }\n",
    "    \n",
    "    :parameter labels: A list where each element represents a sentence, \n",
    "    and each sentence is a list of NER labels for each of its tokens. (Eg. \n",
    "    [['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], [...], ...])\n",
    "    :type labels: List[List[String]]\n",
    "    :parameter k: an optional parameter for smoothing\n",
    "    :type k: int\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    allNER = [item for subNER in labels for item in subNER]\n",
    "    NERs = list(set(allNER))\n",
    "    start_Prob = dict.fromkeys(NERs, 0.0)\n",
    "    count = defaultdict(int)\n",
    "    \n",
    "    for e in labels:\n",
    "        startNER = e[0]\n",
    "        count[startNER] = count[startNER] + 1\n",
    "        \n",
    "    for startNER in NERs:\n",
    "        if startNER in count.keys():\n",
    "            start_Prob[startNER] = np.log((count[startNER]+k)/(len(labels)+k*len(NERs)))\n",
    "        else:\n",
    "            start_Prob[startNER] = np.log(k/(len(labels)+k*len(NERs)))\n",
    "        #start_Prob[startNER] = count[startNER]/len(labels)\n",
    "        \n",
    "    start_Prob['[end]'] = -99999999999999999999\n",
    "    \n",
    "    return start_Prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "LU3Ff-CKInqo"
   },
   "outputs": [],
   "source": [
    "# Takes in the tokens & labels and returns a representation of the HMM.\n",
    "# Call the three functions above in this function to build your HMM.\n",
    "def build_hmm(tokens, labels):\n",
    "    start_Prob = get_start_state_probs(labels,k=0.01)\n",
    "    transition = build_transition_matrix(labels, k=0.02)\n",
    "    emission = build_emission_matrix(tokens, labels,k=0.03)\n",
    "    allTokens = list(set([item for subitem in tokens for item in subitem]))\n",
    "    allLabels = list(set([item for subitem in labels for item in subitem]))\n",
    "    allLabels.append('[end]')\n",
    "    return (allLabels, allTokens, start_Prob, transition, emission)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbw3RTHPI31j"
   },
   "source": [
    "<a name=\"viterbi_implementation\"></a>\n",
    "## **Viterbi Implementation**\n",
    "[[^^^]](#outline) \n",
    "---\n",
    "\n",
    "At the end of your implementation, we expect a function or class that maps a sequence of tokens (observation) to a sequence of labels via the Viterbi algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "C_q3U42lI3LQ"
   },
   "outputs": [],
   "source": [
    "# Takes in the HMM build above and an observation (i.e. a list of tokens),\n",
    "# and returns a list with predicted named entity mappings for the tokens.\n",
    "# The returned list should be the same length as the input obeservation.\n",
    "def viterbi(hmm, observation):\n",
    "    #print(observation)\n",
    "    allNERs, allTokens, start_Prob, transition, emission = hmm\n",
    "    #print(allNERs)\n",
    "    allNERs_noEnd = [NER for NER in allNERs if NER != '[end]']\n",
    "    L = len(observation) # length of the observation list\n",
    "    #print(\"L:\",L)\n",
    "    numNER = len(allNERs)\n",
    "    \n",
    "    for i in range(L):\n",
    "        if observation[i] not in allTokens:\n",
    "            observation[i] = \"<unk>\"\n",
    "        \n",
    "    \n",
    "    observation.append('<end>')\n",
    "    L = len(observation)\n",
    "    #print(observation)\n",
    "    \n",
    "    table = {NER: [[0.0,[]] for col in range(L)] for NER in allNERs}\n",
    "    #print(table)\n",
    "    \n",
    "    for NER in allNERs:\n",
    "        #print(\"NER\",NER)\n",
    "        prob = start_Prob[NER] + emission[(NER,observation[0])]\n",
    "        table[NER][0][0] = prob\n",
    "    #print(table)\n",
    "    \n",
    "    for col in range(1,L): #for each token\n",
    "        #print(col)\n",
    "        for NER1 in allNERs: #for each NER1 row\n",
    "            choices = []\n",
    "            for NER2 in allNERs_noEnd: # for each possible previous NER2\n",
    "                #print(NER1, NER2)\n",
    "                pre = table[NER2][col-1]\n",
    "                #print('pre:', pre)\n",
    "                prob = pre[0] + emission[(NER1,observation[col])] + transition[(NER2,NER1)]\n",
    "                #print(prob)\n",
    "                tags = pre[1]+[NER2]\n",
    "                #print('tags:',tags)\n",
    "                choice = (prob,tags)\n",
    "                choices.append(choice)\n",
    "                #print('choices:', choices)\n",
    "            target = max(choices)\n",
    "            #print(\"target:\",target)\n",
    "            table[NER1][col] = target\n",
    "            #print(\"table22222:\",table)\n",
    "\n",
    "    #print(\"table\",table)\n",
    "    \n",
    "    max_prob = -999999999999999999\n",
    "    max_tags = None\n",
    "    \n",
    "    for NER in allNERs:\n",
    "        prob,tags = table[NER][-1]\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            max_tags = tags\n",
    "    \n",
    "    return max_tags\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEamJbeHrxfm",
    "outputId": "3636982f-7626-46d6-ce4f-5a1f15fbe2c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H', 'C', 'H', 'C']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [['3', '2' ,'3'],['3','1'],['1','3'],['1','1'],['3','1','3']]\n",
    "labels = [['H', 'C','H'],['H','C'],['C','H'],['C','C'], ['H','C','H']]\n",
    "hmm = build_hmm(tokens, labels)\n",
    "\n",
    "viterbi(hmm,['3','1','3','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drUIhqRPFoF1"
   },
   "source": [
    "# HMM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "XRZUmqGbFnSE"
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: please change the line below with your drive organization\n",
    "path = os.path.join(os.getcwd(),\"cs-4740-fa22-hw1-named-entity-recognition\")\n",
    "\n",
    "with open(os.path.join(path,'train.json'), 'r') as f:\n",
    "     train = json.loads(f.read())\n",
    "\n",
    "with open(os.path.join(path,'val.json'), 'r') as f:\n",
    "     val = json.loads(f.read())\n",
    "\n",
    "with open(os.path.join(path,'test.json'), 'r') as f:\n",
    "     test = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "sv6gjhihFsuv"
   },
   "outputs": [],
   "source": [
    "#train_text_lowered = lowerCase(train['text'])\n",
    "#train_text = unknown_word_handling(train_text_lowered,0.2)\n",
    "train_text = unknown_word_handling(train['text'],0.15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "v994c0v-xZN5"
   },
   "outputs": [],
   "source": [
    "hmm = build_hmm(train_text,train['NER'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ie6NXgJAKOEM",
    "outputId": "0dbbee7e-11a2-49fa-de5e-0270ca80c73e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'O']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's a sample observations that you can use to test your code\n",
    "obs_1 = ['Cornell',\n",
    " 'University',\n",
    " 'is',\n",
    " 'located',\n",
    " 'in',\n",
    " 'Ithaca',\n",
    " 'and',\n",
    " 'was',\n",
    " 'founded',\n",
    " \"by\", \"Ezra\", \"Cornell\", \".\" ]\n",
    "\n",
    "# Uncomment and fill out the following line to test your implementation:\n",
    "viterbi(hmm, obs_1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2J8NdM_V_A4u"
   },
   "source": [
    "## **Validation Step**\n",
    "<a name=\"validation_data\"></a>\n",
    "[[^^^]](#outline) \n",
    "---\n",
    "\n",
    "In this part of the project, we expect you to train your HMM model (i.e., get transition and emission probabilities) on the labeled training data and evaluate it on the validation data. Report **Entity Level Mean F1**, which was explained earlier. Please use the code we have provided below to compute this metric.\n",
    "\n",
    "Please also take a look into your misclassified cases, as we will be performing error analysis in the *Evaluation* section. We expect smoothing, unknown word handling and correct emission (i.e., lexical generation) probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTAhu_TG1V0R"
   },
   "source": [
    "Consider the example below. After getting a sequence of NER labels for the sequence of tokens from your Viterbi algorithm implementation, you need to convert the sequence of tokens, associated token indices and NER labels into a format which can be used to calculate **Entity Level Mean F1**. We do this by finding the starting and ending indices of the spans representing each entity (as given in the corpus) and adding it to a list that is associated with the label with which the spans are labelled. To score your validation data on Google Colab or your local device, you can get a dictionary format as shown in the picture below from the function **format_output_labels** of both the predicted and true label sequences, and use the two dictionaries as input to the **mean_f1** function.\n",
    "\n",
    "NOTE: We do **not** include the spans of the tokens labelled as \"O\" in the formatted dictionary output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "HdOOQdN7D2rv"
   },
   "outputs": [],
   "source": [
    "def format_output_labels(token_labels, token_indices):\n",
    "    \"\"\"\n",
    "    Returns a dictionary that has the labels (LOC, ORG, MISC or PER) as the keys, \n",
    "    with the associated value being the list of entities predicted to be of that key label. \n",
    "    Each entity is specified by its starting and ending position indicated in [token_indices].\n",
    "\n",
    "    Eg. if [token_labels] = [\"B-ORG\", \"I-ORG\", \"O\", \"O\", \"B-ORG\"]\n",
    "           [token_indices] = [15, 16, 17, 18, 19]\n",
    "        then dictionary returned is \n",
    "        {'LOC': [], 'MISC': [], 'ORG': [(15, 16), (19, 19)], 'PER': []}\n",
    "\n",
    "    :parameter token_labels: A list of token labels (eg. B-PER, I-PER, B-LOC, I-LOC, B-ORG, I-ORG, B-MISC, OR I-MISC).\n",
    "    :type token_labels: List[String]\n",
    "    :parameter token_indices: A list of token indices (taken from the dataset) \n",
    "                              corresponding to the labels in [token_labels].\n",
    "    :type token_indices: List[int]\n",
    "    \"\"\"\n",
    "    label_dict = {\"LOC\":[], \"MISC\":[], \"ORG\":[], \"PER\":[]}\n",
    "    prev_label = 'O'\n",
    "    start = token_indices[0]\n",
    "    for idx, label in enumerate(token_labels):\n",
    "        curr_label = label.split('-')[-1]\n",
    "        if label.startswith('B-') or curr_label != prev_label:\n",
    "            if prev_label != 'O':\n",
    "                label_dict[prev_label].append((start, token_indices[idx-1]))\n",
    "            if curr_label != 'O':\n",
    "                start = token_indices[idx]\n",
    "            else:\n",
    "                start = None\n",
    "      \n",
    "        prev_label = curr_label\n",
    "\n",
    "    if start is not None and prev_label != 'O':\n",
    "        label_dict[prev_label].append((start, token_indices[idx]))\n",
    "    return label_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "lfjVJLNhL_fc"
   },
   "outputs": [],
   "source": [
    "# Code for mean F1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mean_f1(y_pred_dict, y_true_dict):\n",
    "    \"\"\" \n",
    "    Calculates the entity-level mean F1 score given the actual/true and \n",
    "    predicted span labels.\n",
    "    :parameter y_pred_dict: A dictionary containing predicted labels as keys and the \n",
    "                            list of associated span labels as the corresponding\n",
    "                            values.\n",
    "    :type y_pred_dict: Dict<key [String] : value List[Tuple]>\n",
    "    :parameter y_true_dict: A dictionary containing true labels as keys and the \n",
    "                            list of associated span labels as the corresponding\n",
    "                            values.\n",
    "    :type y_true_dict: Dict<key [String] : value List[Tuple]>\n",
    "\n",
    "    Implementation modified from original by author @shonenkov at\n",
    "    https://www.kaggle.com/shonenkov/competition-metrics.\n",
    "    \"\"\"\n",
    "    F1_lst = []\n",
    "    valid_dict={}\n",
    "    for key in y_true_dict:\n",
    "        TP, FN, FP = 0, 0, 0\n",
    "        num_correct, num_true = 0, 0\n",
    "        preds = y_pred_dict[key]\n",
    "        trues = y_true_dict[key]\n",
    "        for true in trues:\n",
    "            num_true += 1\n",
    "            if true in preds:\n",
    "                num_correct += 1\n",
    "            else:\n",
    "                continue\n",
    "        num_pred = len(preds)\n",
    "        if num_true != 0:\n",
    "            if num_pred != 0 and num_correct != 0:\n",
    "                R = num_correct / num_true\n",
    "                P = num_correct / num_pred\n",
    "                F1 = 2*P*R / (P + R)\n",
    "            else:\n",
    "                F1 = 0      # either no predictions or no correct predictions\n",
    "        else:\n",
    "            continue\n",
    "        valid_dict[key] = [num_correct,num_true,num_pred]\n",
    "        F1_lst.append(F1)\n",
    "    #print(valid_dict)\n",
    "    return np.mean(F1_lst),valid_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC': [118, 225, 141], 'MISC': [60, 165, 88], 'ORG': [35, 95, 55], 'PER': [108, 192, 117]}\n",
      "Entity document Mean F1 score is :  0.5058374542124542\n"
     ]
    }
   ],
   "source": [
    "# Evaluate/validate your model here\n",
    "\n",
    "F1 = []\n",
    "summ = {\"LOC\":[0,0,0], \"MISC\":[0,0,0], \"ORG\":[0,0,0], \"PER\":[0,0,0]}\n",
    "for i in range(len(val['text'])):\n",
    "    obs = val['text'][i]\n",
    "    true_token_labels = val['NER'][i]\n",
    "    token_indices = val['index'][i]\n",
    "    pred_token_labels = viterbi(hmm, obs)\n",
    "    y_pred_dict = format_output_labels(pred_token_labels, token_indices)\n",
    "    #print(\"y_pred_dict is : \" + str(y_pred_dict))\n",
    "    y_true_dict = format_output_labels(true_token_labels, token_indices)\n",
    "    #print(\"y_true_dict is : \" + str(y_true_dict))\n",
    "    #print(mean_f1(y_pred_dict, y_true_dict))\n",
    "    f1 = mean_f1(y_pred_dict, y_true_dict)[0]\n",
    "    dic = mean_f1(y_pred_dict,y_true_dict)[1]\n",
    "    #print(dic)\n",
    "    for key in summ:\n",
    "        if key in dic.keys():\n",
    "            for i in range(0,3):\n",
    "                summ[key][i] = dic[key][i] + summ[key][i]\n",
    "    #print(summ)\n",
    "    F1.append(f1)\n",
    "\n",
    "meanF1 = np.mean(F1)\n",
    "print(summ)\n",
    "print(\"Entity document Mean F1 score is : \", meanF1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC': {'Recall': 0.5244444444444445, 'Precision': 0.8368794326241135, 'F1': 0.6448087431693991}, 'MISC': {'Recall': 0.36363636363636365, 'Precision': 0.6818181818181818, 'F1': 0.4743083003952569}, 'ORG': {'Recall': 0.3684210526315789, 'Precision': 0.6363636363636364, 'F1': 0.4666666666666667}, 'PER': {'Recall': 0.5625, 'Precision': 0.9230769230769231, 'F1': 0.6990291262135923}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = {\"LOC\":{\"Recall\":[],\"Precision\":[],\"F1\":[]}, \"MISC\":{\"Recall\":[],\"Precision\":[],\"F1\":[]}, \"ORG\":{\"Recall\":[],\"Precision\":[],\"F1\":[]}, \"PER\":{\"Recall\":[],\"Precision\":[],\"F1\":[]}}\n",
    "for key in summ.keys():\n",
    "    result[key]['Recall'] = summ[key][0]/summ[key][1]\n",
    "    result[key]['Precision'] = summ[key][0]/summ[key][2]\n",
    "    result[key]['F1'] = (2*result[key]['Recall']*result[key]['Precision'])/(result[key]['Recall']+result[key]['Precision'])\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRLi5TDyuSx_"
   },
   "source": [
    "<a name=\"q2.1\"></a>\n",
    "[[^^^]](#outline) \n",
    "## **Q2.1: Explain your HMM Implementations**\n",
    "\n",
    "Explain how you implemented the HMM including the Viterbi algorithm. Make clear which parts were implemented from scratch vs. obtained via an existing package (review the Logistics section for information on packages that are not allowed). Explain and motivate any design choices providing the intuition behind them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL2bUPVkNpbt"
   },
   "source": [
    "#### **A2.1:**\n",
    "\n",
    "The first part is unknown word handling. In our algorithm, we choose the second alternative listed in Jurafsky and Martin's book. The main idea is to replace the words in training data with <unk> based on their frequency. Since the frequency distribution is skewed, we didn't replace words whose frequency is smaller than a certain value. Most of the words have 1 or 2 frequencies, but some common words like \"the\" and \"a\" and large frequencies. Using certain values to replace words with <unk> will make us lose a lot of informative words. Thus, we choose to replace words based on quantiles like the last 20%. The function is named `unknown_word_handling(tokens,percent)`. The input has two parameters, one is the original document text and the other is the quantile. <br>\n",
    "    \n",
    "Then we start to build three main parts of the Viterbi algorithm. <br>\n",
    "    \n",
    "The first part is generating the transition matrix. The function is named `build_transition_matrix(labels, k)` . The transition probability is the probability of one tag depending on the given previous tag, which is ``P(tag1|tag2)``. Also, to specify the end state, we choose to append a [end] tag at the end of the sentence. Since some of the tag combinations will have 0 occurrences and the logarithm for 0 doesn't exist, we try to smooth this probability by adding a specific value k.<br>\n",
    "    \n",
    "The second part is generating the emission matrix. The function is named `build_emission_matrix(tokens, labels, k)`. The emission probability is the probability of one word depending on a given tag, which is `P(word|tag)`. We also include a <end> word in the word lists to specify the end state and include k to smooth the 0 probabilities. Since there is a (<end>,[end]) combination, we assigned log(1) to this probability and it will not affect the result. <br>\n",
    "The third part is generating the start state. The function is named `get_start_state_probs(labels, k)`. We need to get q0 in the Viterbi chart. The start probability is the probability of each tag appearing at the beginning of a sentence. <br>\n",
    "    \n",
    "In the function `build_hmm(tokens, labels)`, we input the training labels and tokens, as well as call the three functions above to return the matrices that are needed by the Viterbi algorithm. Also, in this function, we can specify different smoothing parameters k. The output is the unzipped label list, token list, start probabilities, transition matrix, and emission matrix. <br>\n",
    "    \n",
    "After that, we input all of the above to build a Viterbi algorithm called viterbi(hmm, observation). The parameter observation is the actual test/validation data and hmm is the inputs from the build_hmm() function. We initialized a table to store all probabilities and states recorded in each step. Also, we use the same logic as above the deal with unknown words that appear in the test data. The start state is the start probabilities times the first words emission probabilities. In the loops, each iteration we compare the probabilities of previous step times emission and transition probabilities. Then, we create a list ` choice` to record each steps best choice tags and the maximized probabilities. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHbzRuil-yjG"
   },
   "source": [
    "<a name=\"q2.2\"></a>\n",
    "[[^^^]](#outline) \n",
    "## **Q2.2: Results Analysis**\n",
    "\n",
    "Explain here how you evaluated the models. Summarize the performance of your system and any variations that you experimented with on the validation datasets. Put the results into clearly labeled tables or diagrams and include your observations and analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_aBZqFKOKRO"
   },
   "source": [
    "#### **A2.2:**\n",
    "\n",
    "We evaluated the models using the F1 score calculated by the provided function. The entity document Mean F1 score on the validation data is 0.5058. We experimented with different parameters on unknown word handling (below which frequency we change the word into <unk>), transition/start probability smoothing parameters, and emission smoothing parameters. We did not record all the experiment results, but below is a table for some experiment we have done and how do they influence the performance of HMM model.\n",
    "\n",
    "| unknown word handling percentage | smoothing (transition/start) | smoothing (emission) | F1 |\n",
    "| --- | --- | --- | ---|\n",
    "| 0 | 0 | 0  | 0\n",
    "| 0.1 | 1 | 1 | 0.23 |\n",
    "| 0.15 | 1 | 1 | 0.25 |\n",
    "| 0.15 | 0.1 | 0.1 | 0.46 |\n",
    "| 0.15 | 0.02 | 0.03 | 0.50 |\n",
    "    \n",
    "We observe that the best parameters of the smoothing are very small (smaller than 0.1). We chose 1 as the parameter for smoothing in the first try and this did not work. We guess it is because there are many words with only 1 occurance in the trainning data, if we add 1 for the smoothing reason, the model cannot tell the probablistic differences between smoothing and actual word in the data.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTIPGnLFNc43"
   },
   "source": [
    "<a name=\"q2.3\"></a>\n",
    "[[^^^]](#outline) \n",
    "## **Q2.3: Error Analysis**\n",
    "When did the system work well? When did it fail?  Any ideas as to why? How might you improve the system?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>MISC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.524444</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.836879</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.644809</td>\n",
       "      <td>0.474308</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.699029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LOC      MISC       ORG       PER\n",
       "Recall     0.524444  0.363636  0.368421  0.562500\n",
       "Precision  0.836879  0.681818  0.636364  0.923077\n",
       "F1         0.644809  0.474308  0.466667  0.699029"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.DataFrame.from_dict(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7j0YVozOMIT"
   },
   "source": [
    "#### **A2.3:**\n",
    "\n",
    "The overall F1 score of HMM model with respect to the validation data is 0.5058. According the previous table, we can see different tags have different recall, precision and F1 scores. The recall is #Correct NEs / # Predicted NEs, the precision is #Correct NEs / #NEs in answer key, and the F-Measure(F1) is 2PR / (P+R). In our model, this table shows that the PER tags have the best performance, with the highest F1 score of 0.699, the recall of 0.563, the precision of 0.923. According to the definition of recall, we can say there are about 56.3% trure PER tags are correctly detected by the HMM model. The LOC has relatively good performance, and MISC is a bit worse. The ORG tags have the worst performance, with the lowest F1 score of 0.466, the recall of 0.368 and the precision of 0.636. The result depicted that this system works well when recognizing person's names and locations, but it fails when recognizing organization names and miscellaneous entities. <br> \n",
    "\n",
    "This probably is because persons' names and locations' names have some simpler rules to follow, like first name plus last name, or location name plus city or town. However, the organization names and miscellaneous entities may have more complex rules, some of them may contain non-informative words like\"the\",\"of\",\"a\" inside these names. Also, this probably is because persons' names and locations' names have less words, maybe one or two, but organization can have long combination of words, which are difficult to detect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mf6ziT36NteS"
   },
   "source": [
    "<a name=\"q2.4\"></a>\n",
    "[[^^^]](#outline) \n",
    "## **Q2.4: What is the effect of unknown word handling and smoothing?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9PL6823OQPT"
   },
   "source": [
    "#### **A2.4:**\n",
    "\n",
    "The effect of unknown word handling is to avoid the situation that the observation string cannot be captured by our hmm model because it does not occur in our training data. Our unknown word handling implementation is choosing a certain percentage of frequency level n and then changing all the words with frequency lower than n into <unk>. If we encounter unknown word in our observation, we replace it with <unk>.\n",
    "    \n",
    "Training data cannot fully reflect the real world. The effect of smoothing is to make sure all NER sequences (in transition probability) and all NER-word pair (in emission probability) can occur with some probability, so that even though we do not see certain sequence or pair in the trainning data, they still have some possibility of occuring in the observation.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31e3sMHZrLWP"
   },
   "source": [
    "<a name=\"part3\"></a>\n",
    "# **Part 3: Maximum Entropy Markov Model** \n",
    "[[^^^]](#outline) \n",
    "---\n",
    "\n",
    "In this section, you will implement a Maximum Entropy Markov Model (**MEMM**) to perform the same NER task. Your model should consist of a MaxEnt classifier with Viterbi decoding. \n",
    "\n",
    "1. We have already performed tokenizations for documents. You can either use a MaxEnt classifier from an existing package or write the MaxEnt code yourself. **Important note:  MaxEnt classifiers are statistically equivalent to multi-class logistic regression, so you can use packages for multi-class LR instead of MaxEnt.**\n",
    "\n",
    "2. Use the classifier to learn a probability $P(t_i|features)$. You may replace either the lexical generation probability  $P(w_i|t_i)$  or the transition probability  $P(t_i|t_{i1})$  in the HMM with it, or you may replace the entire *lexical generation probability * transition probability*  calculation  $P (w_i|t_i)  P (t_i|t_{i1)}  $ in the HMM with it. \n",
    "\n",
    "3. To train such a classifier, you need to pick some feature set. The content of the feature set is up to you, but try different ones, and evaluate your choices on the validation set. Pick the feature set that performs overall the best according to the F1 measure. If you draw inspiration for your features from external sources, please link them in the code.\n",
    "  * While there are many directions to take when looking for features, you may start by exploring parts of speech that appear in sentences. There are several libraries (ex. [nltk](https://www.nltk.org/book/ch05.html)) that process sentences and identify parts of speech. If you end up using a library to extract parts of speech tags or other features, please indicate this in your asnwer to Q3.1.\n",
    "\n",
    "4. Use your own implementation of the **Viterbi algorithm**, which you can modify from the one you developed for the HMM model. You will need the probabilities that you obtain from the MaxEnt classifier. \n",
    "\n",
    "5. Remember to use same training and validation split when evaluating the MEMM to have a **fair comparison** with your **HMM model**.\n",
    "\n",
    "\n",
    "Please also take a look into your misclassified cases, as we will be performing error analysis in Part 4. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJIosHVJZ-1o"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "Here's a summary of the workflow for Part 3:\n",
    "\n",
    "![alt text](https://drive.google.com/uc?export=view&id=14VfjW3yDyXLojWM_u0LeJYdDOSLkElBn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QGSijPUW_Bi"
   },
   "source": [
    "Note that we have not provided any skeleton code for how you should do feature engineering since this is meant to be an open ended task and we want you to experiment with the dataset. However, please remember to make sure that you code is concise, clean, and readable! Ultimately, we expect a function or class  mapping a sequence of tokens to a sequence of labels. At the end of this section you should have done the following:\n",
    "1. Extract Features\n",
    "2. Build & Train MaxEnt\n",
    "3. Call Viterbi when evaluating\n",
    "\n",
    "### References\n",
    "You may find [chapter 8](https://web.stanford.edu/~jurafsky/slp3/8.pdf) of Jurafsky and Martin book useful. In particular, you could consider section 8.5.2 for features in NER. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pd2PwG4wYkhQ"
   },
   "source": [
    "<a name=\"features\"></a>\n",
    "## **Feature Engineering**\n",
    "[[^^^]](#outline) \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "xJR7yKDdNlQr"
   },
   "outputs": [],
   "source": [
    "# a function that look at the data in details to help us choose feature\n",
    "def look_data(tokens, ners, i):\n",
    "    output = []\n",
    "    for j in range(len(tokens[i])):\n",
    "        label = ners[i][j]\n",
    "        if label != 'O':\n",
    "            a = tokens[i][j] + '(' + label + ')'\n",
    "        if label == 'O':\n",
    "            a = tokens[i][j]\n",
    "        output.append(a)\n",
    "    print(' '.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "r_9uve_DNs61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In July 2017 , she was appointed to be the next President of the Supreme(B-ORG) Court(I-ORG) , succeeding Lord Neuberger(B-PER) of Abbotsbury(B-LOC) .\n"
     ]
    }
   ],
   "source": [
    "for i in range(5090,5091):\n",
    "    look_data(train['text'], train['NER'], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "6xBYPGLUHH7n"
   },
   "outputs": [],
   "source": [
    "\n",
    "def feature_extract(tokens,labels =None): \n",
    "    from nltk import pos_tag\n",
    "    output = []\n",
    "    keys =  ['text',\n",
    "             #'pre_text',\n",
    "             #'next_text',\n",
    "             'pos_is_NNP',\n",
    "             \"any_cap\", \n",
    "             \"all_cap\", \n",
    "             #\"contain_digit\", \n",
    "             #\"contain_dot\", \n",
    "             \"sentence_initial\", \n",
    "             #\"sentence_final\",\n",
    "             \"is_loc\",\n",
    "             'is_nationality',\n",
    "             \"pre_B-LOC\", \"pre_B-PER\", \"pre_B-MISC\", \"pre_B-ORG\", 'pre_O',\n",
    "             \"pre_I-LOC\", \"pre_I-PER\", \"pre_I-MISC\", \"pre_I-ORG\",\n",
    "             #\"cur_University\", 'cur_War', \"cur_League\",\n",
    "             \"pre_the\",'pre_by',\n",
    "             'pre_to', 'pre_from', 'pre_of', 'pre_at', 'pre_in','pre_on', 'pre_\"','pre_as',\n",
    "             \"next_University\", 'next_War', \"next_League\"]\n",
    "    \n",
    "    pre_labels = [\"B-LOC\", \"B-PER\", \"B-MISC\", \"B-ORG\", 'O'\n",
    "                  , \"I-LOC\", \"I-PER\", \"I-MISC\", \"I-ORG\"]\n",
    "    pre_words = ['the', 'by'\n",
    "                 , 'to', 'from', 'of', 'at', 'in','on', '\"', 'as']\n",
    "    next_words = ['University', 'War','League']\n",
    "    #current_words = ['University', 'War','League']\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        sentence = tokens[i]\n",
    "        from geotext import GeoText\n",
    "        \n",
    "\n",
    "        \n",
    "        pos_l = pos_tag(sentence)\n",
    "        for j in range(len(sentence)):\n",
    "            token = sentence[j]\n",
    "            \n",
    "            places = GeoText(token)\n",
    "\n",
    "            feature_vec = dict.fromkeys(keys, 0)\n",
    "            feature_vec['text'] = token\n",
    "            feature_vec['pos_is_NNP']  = int(pos_l[j][1] == 'NNP')\n",
    "            feature_vec['all_cap'] = int(token.isupper())\n",
    "            feature_vec['any_cap'] = int(any(map(str.isupper, token))) - feature_vec['all_cap']\n",
    "            feature_vec['sentence_initial'] = int(j == 0)\n",
    "            feature_vec['is_loc'] = int(((token in places.cities) or (token in places.countries)) and token != 'University')\n",
    "            feature_vec['is_nationality'] = int(token in places.nationalities)\n",
    "\n",
    "            # feature_vec['cur_University']  = int(token == 'University')\n",
    "            # feature_vec['cur_War']  = int(token == 'War')\n",
    "            # feature_vec['cur_League']  = int(token == 'League')\n",
    "                    \n",
    "            if (len(sentence) > 1) & (j != len(sentence)-1):\n",
    "                next_word = sentence[j+1]\n",
    "                #feature_vec['next_text'] = next_word\n",
    "                if next_word in next_words:\n",
    "                    feature = \"next_\" + next_word\n",
    "                    #print(feature)\n",
    "                    feature_vec[feature] = 1\n",
    "                    \n",
    "            if j > 0:\n",
    "                pre_NER = labels[i][j-1]\n",
    "                pre_word = sentence[j-1]\n",
    "\n",
    "            \n",
    "                #feature_vec['pre_text'] = pre_word\n",
    "                \n",
    "                if pre_NER in pre_labels:\n",
    "                    feature = \"pre_\" + pre_NER\n",
    "                    feature_vec[feature] = 1\n",
    "                \n",
    "                if pre_word.lower()  in pre_words:\n",
    "                    feature = \"pre_\" + pre_word.lower() \n",
    "                    feature_vec[feature] = 1\n",
    "\n",
    "            \n",
    "            label = labels[i][j]\n",
    "            entry = (feature_vec, label)\n",
    "            output.append(entry)\n",
    "            \n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "o5sEYlGkJYSA"
   },
   "outputs": [],
   "source": [
    "# Your implementation here\n",
    "def test_feature_extract(token, pos, pre_label=None, pre_word = None, next_word=None):\n",
    "\n",
    "    from nltk import pos_tag\n",
    "    from geotext import GeoText\n",
    "    \n",
    "    output = []\n",
    "    keys =  ['text',\n",
    "             #'pre_text',\n",
    "             #'next_text',\n",
    "             'pos_is_NNP',\n",
    "             \"any_cap\", \n",
    "             \"all_cap\", \n",
    "             #\"contain_digit\", \n",
    "             #\"contain_dot\", \n",
    "             \"sentence_initial\", \n",
    "             #\"sentence_final\",\n",
    "             \"is_loc\",\n",
    "             'is_nationality',\n",
    "             \"pre_B-LOC\", \"pre_B-PER\", \"pre_B-MISC\", \"pre_B-ORG\", 'pre_O',\n",
    "             \"pre_I-LOC\", \"pre_I-PER\", \"pre_I-MISC\", \"pre_I-ORG\",\n",
    "             #\"cur_University\", 'cur_War', \"cur_League\",\n",
    "             \"pre_the\",'pre_by',\n",
    "             'pre_to', 'pre_from', 'pre_of', 'pre_at', 'pre_in','pre_on', 'pre_\"','pre_as',\n",
    "             \"next_University\", 'next_War', \"next_League\"]\n",
    "    \n",
    "    pre_labels = [\"B-LOC\", \"B-PER\", \"B-MISC\", \"B-ORG\", 'O'\n",
    "                  , \"I-LOC\", \"I-PER\", \"I-MISC\", \"I-ORG\"]\n",
    "    pre_words = ['the', 'by'\n",
    "                 , 'to', 'from', 'of', 'at', 'in','on', '\"', 'as']\n",
    "    next_words = ['University', 'War','League']\n",
    "    #current_words = ['University', 'War','League']\n",
    "    \n",
    "    \n",
    "    \n",
    "    places  = GeoText(token)\n",
    "    feature_vec = dict.fromkeys(keys, 0)\n",
    "    feature_vec['text'] = token\n",
    "    feature_vec['pos_is_NNP']  = int(pos == 'NNP')\n",
    "    feature_vec['all_cap'] = int(token.isupper())\n",
    "    feature_vec['any_cap'] = int(any(map(str.isupper, token))) - feature_vec['all_cap']\n",
    "    feature_vec['is_loc'] = int((token in places.cities) or (token in places.countries))\n",
    "    feature_vec['is_nationality'] = int(token in places.nationalities)\n",
    "\n",
    "    # feature_vec['cur_University']  = int(token == 'University')\n",
    "    # feature_vec['cur_War']  = int(token == 'War')\n",
    "    # feature_vec['cur_League']  = int(token == 'League')\n",
    "    \n",
    "    # If token is in the begining of the sentence \n",
    "    if pre_label==None:\n",
    "        feature_vec[\"sentence_initial\"] = 1\n",
    "\n",
    "    else:\n",
    "\n",
    "        #feature_vec['pre_text'] = pre_word\n",
    "\n",
    "        if pre_label in pre_labels:\n",
    "            feature = \"pre_\" + pre_label\n",
    "            feature_vec[feature] = 1\n",
    "        \n",
    "        if pre_word.lower() in pre_words:\n",
    "            feature = \"pre_\" + pre_word.lower() \n",
    "            feature_vec[feature] = 1\n",
    "\n",
    "    #feature_vec['next_text'] = next_word\n",
    "    if next_word in next_words:\n",
    "        feature = \"next_\" + next_word\n",
    "        feature_vec[feature] = 1\n",
    "        \n",
    "\n",
    "        \n",
    "    return feature_vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACqYM9I4Jupd",
    "outputId": "ad4be242-1e69-451c-df56-7c53c75b39f1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: please change the line below with your drive organization\n",
    "path = os.path.join(os.getcwd(),\"cs-4740-fa22-hw1-named-entity-recognition\")\n",
    "\n",
    "with open(os.path.join(path,'train.json'), 'r') as f:\n",
    "     train = json.loads(f.read())\n",
    "\n",
    "with open(os.path.join(path,'val.json'), 'r') as f:\n",
    "     val = json.loads(f.read())\n",
    "\n",
    "with open(os.path.join(path,'test.json'), 'r') as f:\n",
    "     test = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "DwH8FtddJw4K"
   },
   "outputs": [],
   "source": [
    "def build_ME(tokens, labels, max_iter):\n",
    "    \n",
    "    train_text_unk = unknown_word_handling(tokens,0.2)\n",
    "    \n",
    "    allTokens = list(set([item for subitem in train_text_unk for item in subitem]))\n",
    "    allLabels = list(set([item for subitem in labels for item in subitem]))\n",
    "    \n",
    "    train_feature = feature_extract(train_text_unk, labels)\n",
    "    from nltk.classify import maxent\n",
    "    encoding = maxent.TypedMaxentFeatureEncoding.train(train_feature)\n",
    "    classifier = maxent.MaxentClassifier.train(train_feature, max_iter=max_iter)\n",
    "    \n",
    "    return classifier, allTokens, allLabels\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCkP4A3IYwit"
   },
   "source": [
    "<a name=\"memm_implementation\"></a>\n",
    "## **MEMM Implementation**\n",
    "[[^^^]](#outline) \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3CuClmDloKd",
    "outputId": "a3ba5e42-2040-487d-f7cf-bc8b873ada57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -2.19722        0.884\n",
      "             2          -0.22478        0.884\n",
      "             3          -0.21897        0.884\n",
      "             4          -0.21201        0.884\n",
      "             5          -0.20419        0.884\n",
      "             6          -0.19595        0.884\n",
      "             7          -0.18767        0.884\n",
      "             8          -0.17960        0.887\n",
      "             9          -0.17192        0.892\n",
      "            10          -0.16471        0.898\n",
      "            11          -0.15801        0.907\n",
      "            12          -0.15181        0.912\n",
      "            13          -0.14611        0.915\n",
      "            14          -0.14085        0.924\n",
      "            15          -0.13602        0.928\n",
      "            16          -0.13158        0.934\n",
      "            17          -0.12749        0.939\n",
      "            18          -0.12372        0.943\n",
      "            19          -0.12024        0.952\n",
      "            20          -0.11702        0.956\n",
      "            21          -0.11404        0.959\n",
      "            22          -0.11127        0.961\n",
      "            23          -0.10870        0.962\n",
      "            24          -0.10629        0.964\n",
      "            25          -0.10405        0.965\n",
      "            26          -0.10195        0.966\n",
      "            27          -0.09998        0.966\n",
      "            28          -0.09813        0.968\n",
      "            29          -0.09639        0.969\n",
      "            30          -0.09474        0.969\n",
      "            31          -0.09319        0.970\n",
      "            32          -0.09172        0.970\n",
      "            33          -0.09033        0.970\n",
      "            34          -0.08900        0.971\n",
      "            35          -0.08775        0.971\n",
      "            36          -0.08655        0.971\n",
      "            37          -0.08541        0.971\n",
      "            38          -0.08432        0.971\n",
      "            39          -0.08328        0.972\n",
      "            40          -0.08228        0.972\n",
      "            41          -0.08132        0.972\n",
      "            42          -0.08041        0.973\n",
      "            43          -0.07953        0.973\n",
      "            44          -0.07868        0.973\n",
      "            45          -0.07787        0.973\n",
      "            46          -0.07708        0.974\n",
      "            47          -0.07632        0.974\n",
      "            48          -0.07559        0.974\n",
      "            49          -0.07489        0.974\n",
      "            50          -0.07421        0.974\n",
      "            51          -0.07355        0.974\n",
      "            52          -0.07291        0.975\n",
      "            53          -0.07229        0.975\n",
      "            54          -0.07170        0.975\n",
      "            55          -0.07112        0.975\n",
      "            56          -0.07055        0.976\n",
      "            57          -0.07000        0.976\n",
      "            58          -0.06947        0.976\n",
      "            59          -0.06896        0.976\n",
      "            60          -0.06845        0.976\n",
      "            61          -0.06796        0.976\n",
      "            62          -0.06749        0.976\n",
      "            63          -0.06702        0.976\n",
      "            64          -0.06657        0.977\n",
      "            65          -0.06613        0.977\n",
      "            66          -0.06570        0.977\n",
      "            67          -0.06528        0.977\n",
      "            68          -0.06487        0.977\n",
      "            69          -0.06447        0.977\n",
      "            70          -0.06408        0.977\n",
      "            71          -0.06370        0.977\n",
      "            72          -0.06333        0.977\n",
      "            73          -0.06296        0.977\n",
      "            74          -0.06260        0.978\n",
      "            75          -0.06226        0.978\n",
      "            76          -0.06191        0.978\n",
      "            77          -0.06158        0.978\n",
      "            78          -0.06125        0.978\n",
      "            79          -0.06093        0.978\n",
      "            80          -0.06061        0.978\n",
      "            81          -0.06031        0.978\n",
      "            82          -0.06000        0.978\n",
      "            83          -0.05971        0.979\n",
      "            84          -0.05942        0.979\n",
      "            85          -0.05913        0.979\n",
      "            86          -0.05885        0.979\n",
      "            87          -0.05858        0.979\n",
      "            88          -0.05831        0.979\n",
      "            89          -0.05804        0.979\n",
      "            90          -0.05778        0.979\n",
      "            91          -0.05752        0.979\n",
      "            92          -0.05727        0.979\n",
      "            93          -0.05703        0.979\n",
      "            94          -0.05678        0.979\n",
      "            95          -0.05654        0.979\n",
      "            96          -0.05631        0.979\n",
      "            97          -0.05608        0.980\n",
      "            98          -0.05585        0.980\n",
      "            99          -0.05563        0.980\n",
      "         Final          -0.05541        0.980\n"
     ]
    }
   ],
   "source": [
    "ME = build_ME(train['text'], train['NER'], max_iter=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('ME.pickle', 'wb')\n",
    "pickle.dump(classifier, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "PuqzLSusJx-e"
   },
   "outputs": [],
   "source": [
    "# Takes in the classifier build above and an observation (i.e. a list of tokens),\n",
    "# and returns a list with predicted named entity mappings for the tokens.\n",
    "# The returned list should be the same length as the input obeservation.\n",
    " \n",
    "        \n",
    "def MEMM(ME, observation):\n",
    "    classifier, allTokens, allNERs = ME\n",
    "    uni_tokens = list(set(allTokens))\n",
    "    L = len(observation) # length of the observation list\n",
    "    #print(\"L:\",L)\n",
    "    numNER = len(allNERs)\n",
    "    observation.append('<end>')\n",
    "    pos_l = pos_tag(observation)\n",
    "    #print(pos_l)\n",
    "    \n",
    "    for i in range(L):\n",
    "        if observation[i] not in allTokens:\n",
    "            observation[i] = \"<unk>\"\n",
    "\n",
    "    \n",
    "    L = len(observation)\n",
    "    \n",
    "    table = {NER: [[0.0,[]] for col in range(L)] for NER in allNERs}\n",
    "    #print(table)\n",
    "    \n",
    "    # First token: start probability\n",
    "    first_token = observation[0]\n",
    "    \n",
    "    if L>1:\n",
    "        next_token = observation[1]\n",
    "    else:\n",
    "        next_token = None\n",
    "    \n",
    "    \n",
    "    first_feature = test_feature_extract(first_token, pos=pos_l[0][1], next_word=next_token)\n",
    "    start_probs = classifier.prob_classify(first_feature)\n",
    "#     print(\"Feature analysis for \", first_token)\n",
    "#     classifier.explain(first_feature)\n",
    "    \n",
    "    for NER in allNERs:\n",
    "        #print(\"NER\",NER)\n",
    "        prob = start_probs.prob(NER)\n",
    "        table[NER][0][0] = np.log(prob)\n",
    "    #print(table)\n",
    "   \n",
    "\n",
    "    #Iteration for the rest of the observation\n",
    "    \n",
    "    for col in range(1,L): #for each token\n",
    "        #print('O:',observation[col])\n",
    "        for NER1 in allNERs: #for each NER1 row\n",
    "            choices = []\n",
    "            for NER2 in allNERs: # for each possible previous NER2\n",
    "                #print(NER1, NER2)\n",
    "                pre = table[NER2][col-1]\n",
    "                #print('pre:', pre)\n",
    "                token = observation[col]\n",
    "                #print(pos_l[col][1])\n",
    "                pos = pos_l[col][1]\n",
    "                pre_label = NER2\n",
    "                pre_word = observation[col-1]\n",
    "                if col != L-1:\n",
    "                    next_word = observation[col+1]\n",
    "                else: next_word = None\n",
    "                \n",
    "                feature = test_feature_extract(token, pos=pos, pre_label=pre_label, pre_word = pre_word, next_word=next_word)\n",
    "                classify_probs = classifier.prob_classify(feature)\n",
    "                prob_ner = classify_probs.prob(NER1)\n",
    "#                 print(\"Feature analysis for \", token, \"with pre_NER = \", NER2)\n",
    "#                 classifier.explain(feature)\n",
    "                \n",
    "                if prob_ner == 0:\n",
    "                    prob_ner == 0.000000000000000000001\n",
    "            \n",
    "                prob = pre[0] + np.log(prob_ner)\n",
    "                \n",
    "                #print(prob)\n",
    "                tags = pre[1]+[NER2]\n",
    "                #print('tags:',tags)\n",
    "                \n",
    "                choice = (prob,tags)\n",
    "                choices.append(choice)\n",
    "                #print('choices:', choices)\n",
    "            target = max(choices)\n",
    "            #print(\"target:\",target)\n",
    "            table[NER1][col] = target\n",
    "            #print(\"table22222:\",table)\n",
    "\n",
    "    #print(\"table\",table)\n",
    "    \n",
    "    max_prob = -999999999999999999\n",
    "    max_tags = None\n",
    "    \n",
    "    for NER in allNERs:\n",
    "        prob,tags = table[NER][-1]\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            max_tags = tags\n",
    "    \n",
    "    return max_tags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xH1RNtjwWLde",
    "outputId": "11512a7c-ca90-41eb-80cf-3d4ce96fd442"
   },
   "outputs": [],
   "source": [
    "classifier, allTokens, allLabels = ME\n",
    "#classifier.show_most_informative_features(n=2000, show=\"all\")\n",
    "#classifier.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# f = open('ME.pickle', 'rb')\n",
    "# classifier2 = pickle.load(f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKjbGZnEWRE1",
    "outputId": "34ee4386-63ce-4cf7-a345-7ff6eb473d09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-PER',\n",
       " 'I-PER',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-PER',\n",
       " 'I-PER',\n",
       " 'O']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's a sample observations that you can use to test your code\n",
    "obs = ['Cornell',\n",
    " 'University',\n",
    " 'is',\n",
    " 'located',\n",
    " 'in',\n",
    " 'Ithaca',\n",
    " 'and',\n",
    " 'was',\n",
    " 'founded',\n",
    " \"by\", \"Ezra\", \"Cornell\", \".\" ]\n",
    "\n",
    "MEMM(ME, obs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvoeAVMlX4gp"
   },
   "source": [
    "### **Validation**\n",
    "---\n",
    "In this section we want you to run your MaxEnt model on the validation dataset you extracted earlier. We want you to play around with different combinations of features in order to find which features work the best for your implementation. You will be asked to write about this process in detail in written question 3.3 so please spend time experimenting with features! Once again, please use the code we provided for computing Entity Level Avg F1 earlier when validating your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "TmUnuuxvHKXM"
   },
   "outputs": [],
   "source": [
    "# Run your model on validation set\n",
    "# You will need to \n",
    "# 1. Call your function above to get a prediction result on Validation Set\n",
    "# 2. Report Metrics\n",
    "# (See if you need to modify your feature set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for mean F1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mean_f1(y_pred_dict, y_true_dict):\n",
    "    \"\"\" \n",
    "    Calculates the entity-level mean F1 score given the actual/true and \n",
    "    predicted span labels.\n",
    "    :parameter y_pred_dict: A dictionary containing predicted labels as keys and the \n",
    "                            list of associated span labels as the corresponding\n",
    "                            values.\n",
    "    :type y_pred_dict: Dict<key [String] : value List[Tuple]>\n",
    "    :parameter y_true_dict: A dictionary containing true labels as keys and the \n",
    "                            list of associated span labels as the corresponding\n",
    "                            values.\n",
    "    :type y_true_dict: Dict<key [String] : value List[Tuple]>\n",
    "\n",
    "    Implementation modified from original by author @shonenkov at\n",
    "    https://www.kaggle.com/shonenkov/competition-metrics.\n",
    "    \"\"\"\n",
    "    F1_lst = []\n",
    "    valid_dict={}\n",
    "    for key in y_true_dict:\n",
    "        TP, FN, FP = 0, 0, 0\n",
    "        num_correct, num_true = 0, 0\n",
    "        preds = y_pred_dict[key]\n",
    "        trues = y_true_dict[key]\n",
    "        for true in trues:\n",
    "            num_true += 1\n",
    "            if true in preds:\n",
    "                num_correct += 1\n",
    "            else:\n",
    "                continue\n",
    "        num_pred = len(preds)\n",
    "        if num_true != 0:\n",
    "            if num_pred != 0 and num_correct != 0:\n",
    "                R = num_correct / num_true\n",
    "                P = num_correct / num_pred\n",
    "                F1 = 2*P*R / (P + R)\n",
    "            else:\n",
    "                F1 = 0      # either no predictions or no correct predictions\n",
    "        else:\n",
    "            continue\n",
    "        valid_dict[key] = [num_correct,num_true,num_pred]\n",
    "        F1_lst.append(F1)\n",
    "    #print(valid_dict)\n",
    "    return np.mean(F1_lst),valid_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gs-v0unylsRu",
    "outputId": "79eba9d6-db37-4db1-dbdf-71751770c8fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity document Mean F1 score is :  0.5060831088845795\n"
     ]
    }
   ],
   "source": [
    "# Evaluate/validate your model here\n",
    "\n",
    "F1 = []\n",
    "summ2 = {\"LOC\":[0,0,0], \"MISC\":[0,0,0], \"ORG\":[0,0,0], \"PER\":[0,0,0]}\n",
    "for i in range(len(val['text'])):\n",
    "    obs = val['text'][i]\n",
    "    true_token_labels = val['NER'][i]\n",
    "    token_indices = val['index'][i]\n",
    "    pred_token_labels = MEMM(ME, obs)\n",
    "    y_pred_dict = format_output_labels(pred_token_labels, token_indices)\n",
    "    #print(\"y_pred_dict is : \" + str(y_pred_dict))\n",
    "    y_true_dict = format_output_labels(true_token_labels, token_indices)\n",
    "    #print(\"y_true_dict is : \" + str(y_true_dict))\n",
    "    #print(mean_f1(y_pred_dict, y_true_dict))\n",
    "    f1 = mean_f1(y_pred_dict, y_true_dict)[0]\n",
    "    dic = mean_f1(y_pred_dict,y_true_dict)[1]\n",
    "    #print(dic)\n",
    "    for key in summ2:\n",
    "        if key in dic.keys():\n",
    "            for i in range(0,3):\n",
    "                summ2[key][i] = dic[key][i] + summ2[key][i]\n",
    "    #print(summ)\n",
    "    F1.append(f1)\n",
    "\n",
    "meanF1 = np.mean(F1)\n",
    "print(\"Entity document Mean F1 score is : \", meanF1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC': {'Recall': 0.5422222222222223, 'Precision': 0.8591549295774648, 'F1': 0.6648501362397821}, 'MISC': {'Recall': 0.3515151515151515, 'Precision': 0.7945205479452054, 'F1': 0.48739495798319327}, 'ORG': {'Recall': 0.35789473684210527, 'Precision': 0.8292682926829268, 'F1': 0.4999999999999999}, 'PER': {'Recall': 0.5572916666666666, 'Precision': 0.9224137931034483, 'F1': 0.6948051948051949}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result2 = {\"LOC\":{\"Recall\":[],\"Precision\":[],\"F1\":[]}, \"MISC\":{\"Recall\":[],\"Precision\":[],\"F1\":[]}, \"ORG\":{\"Recall\":[],\"Precision\":[],\"F1\":[]}, \"PER\":{\"Recall\":[],\"Precision\":[],\"F1\":[]}}\n",
    "for key in summ2.keys():\n",
    "    result2[key]['Recall'] = summ2[key][0]/summ2[key][1]\n",
    "    result2[key]['Precision'] = summ2[key][0]/summ2[key][2]\n",
    "    result2[key]['F1'] = (2*result2[key]['Recall']*result2[key]['Precision'])/(result2[key]['Recall']+result2[key]['Precision'])\n",
    "#print(result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>MISC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.542222</td>\n",
       "      <td>0.351515</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>0.557292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.922414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.664850</td>\n",
       "      <td>0.487395</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.694805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LOC      MISC       ORG       PER\n",
       "Recall     0.542222  0.351515  0.357895  0.557292\n",
       "Precision  0.859155  0.794521  0.829268  0.922414\n",
       "F1         0.664850  0.487395  0.500000  0.694805"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGkhL1imxpmH"
   },
   "source": [
    "<a name=\"q3.1\"></a>\n",
    "[[^^^]](#outline) \n",
    "\n",
    "## **Q3.1: Implementation Details**\n",
    "Explain how you implemented the MEMM and whether/how you modified Viterbi (e.g. which algorithms/data structures you used, what features are included). Make clear which parts were implemented from scratch vs. obtained via an existing package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etkqBEJxOZbI"
   },
   "source": [
    "#### **A3.1:**\n",
    "\n",
    "1. We first decided what features should we choose for MEMM. By looking at data closely, we decided to use the following feature list:\n",
    "             ['text'\n",
    "             'pos_is_NNP',\n",
    "             \"any_cap\", \n",
    "             \"all_cap\",\n",
    "             \"sentence_initial\", \n",
    "             \"is_loc\",\n",
    "             'is_nationality',\n",
    "             \"pre_B-LOC\", \"pre_B-PER\", \"pre_B-MISC\", \"pre_B-ORG\", 'pre_O',\n",
    "             \"pre_I-LOC\", \"pre_I-PER\", \"pre_I-MISC\", \"pre_I-ORG\",\n",
    "             \"pre_the\",'pre_by',\n",
    "             'pre_to', 'pre_from', 'pre_of', 'pre_at', 'pre_in','pre_on', 'pre_\"','pre_as',\n",
    "             \"next_University\", 'next_War', \"next_League\"]\n",
    "             \n",
    "2. Then we started to implement two feature extractions, one for training data and one for observation. In the feature extraction process, we use nltk pos_tag and geotext GeoText for the features ['pos_is_NNP'], [\"is_loc\"], and ['is_nationality']. \n",
    "\n",
    "    2.1 feature extractions for training data: The output data structure is a list of tuples with the first element be the feature dictionary and the second element be the NER label. We looped through every word in every sentence in the data. And then first check for features about the word itself, like captalization, pos_is_NNP, is_loc, etc. Then check if the word is sentence initial, if not, we check the previous word and the NER of previous word. Then if the sentence length > 1 and the current word is not the last element in the sentence, we check the next word of it to see if it is in the next_word list which includes 'University', 'War', 'League', 'Mountains'.\n",
    "\n",
    "     2.2 feature extractions for testing data: The output data structure is a feature dictionary. Unlike the training feature extraction, it takes more input: the current single word, its part-of-speech, the NER of previous word, the previous word, and the next word. The MEMM viterbi will produce those inputs to be used in this function. Then the function maps all the input into the feature dictionary.\n",
    "\n",
    "\n",
    "3. Build the ME model: we first do the unknown-word-handling. And then use 2.1 to extract training feature data. Then we obtained an exsiting package -- nltk.classify.maxent -- to train our maxent classifier. Then we return the classifier, all tokens, and all NERs.\n",
    "\n",
    "\n",
    "4. MEMM implementation: We modified viterbi from last HMM section. Since we do not have start probability anymore, we initialize the table by calling the test_feature_extract on the first element and then use the classifier from ME model to generate the probability distribution for each NER label. Then we have three loops, 1. iterate the observation from the second word to the end; 2. iterate all NER for each row; 3. iterate all NER again for each possible previous NER. Then we check all inputs for test_feature_extract and then extract feature for every word. Then the ME classifier was used to calculated the probability distribution for each NER label. We use the probability distribution to update the table. So instead of log(emission) + log(transition) in HMM, we only have one single log(ME_probability) in MEMM. The rest of the MEMM viterbi is similiar to HMM viterbi.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_eDwiILvHGL"
   },
   "source": [
    "<a name=\"q3.2\"></a>\n",
    "[[^^^]](#outline) \n",
    "\n",
    "## **Q3.2: Results Analysis**\n",
    "Explain here how you evaluated the MEMM model. Summarize the performance of your system and any variations that you experimented with the validation datasets. Put the results into clearly labeled tables or diagrams and include your observations and analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udTvSjp1ObVy"
   },
   "source": [
    "#### **A3.2:**\n",
    "\n",
    "We evaluated the MEMM models using the F1 score calculated by provided functions. The entity document Mean F1 score on the validation data is 0.5061. We experimented with different feature sets and iteration number. We did not record all the experiment results, but below is an approximate process of experimenting the feature sets and the iteration number. \n",
    "\n",
    "| Features | iteration | Accuracy | time(min) |\n",
    "| --- | --- | --- | ---|\n",
    "| all_cap, any_cup, sent_init | 10 | 0.0004  | ~10\n",
    "| + current token, POS | 20 | 0.23 | ~60 |\n",
    "| + pre_NER(binary)| 20 | 0.30 | ~70 |\n",
    "| + is_Loc, is_nationality, pre_word(binary), next_word(binary)| 20 | 0.35 | ~70 |\n",
    "| + is_Loc, is_nationality, pre_word(binary), next_word(binary)| 300 | 0.40 | ~900 |\n",
    "| + is_Loc, is_nationality, pre_word(binary), next_word(binary)| 100 | 0.50 | ~300 |\n",
    "\n",
    "We first just had simple features about the word itself with binary values, like capitalization. After 10 times of iteration, the accuracy was very low. Therefore, we keep adding more informative features. An interesting thing we observed was that sometimes adding more features lowered the accuracy. We thought this was because the added features were not informative enough and even disrupted the learning process of the model. Another thing we observed was that with increasing iteration number to a very big number actually worsened the model performance. We thought this was because overfitting. The model was too closely aligned to the training data and performed poorly in test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ammZn20RZn8h"
   },
   "source": [
    "<a name=\"q3.3\"></a>\n",
    "[[^^^]](#outline) \n",
    "\n",
    "## **Q3.3: Feature Engineering**\n",
    "What features are considered most important by your MaxEnt Classifier? Why do you think these features make sense? Describe your experiments with feature sets. An analysis on feature selection for the MEMM is required  e.g. what features **help most**, why? An **error analysis** is required  e.g. what sorts of errors occurred, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foadgkcOOcvT"
   },
   "source": [
    "#### **A3.3:**\n",
    "\n",
    "We have three kinds of features: (i) feature about the current token, like captalization, part-of-speech, if-it-is-location, etc; (ii) the label of previous token: pre_B-Loc, pre_O, etc; (iii) if the previous and next words are worth-noting: pre_the, pre_by, etc. The list of word is chosen by looking at the training data. For example we found that the named entities are more likely to occur after certain preposition/determiners, and different preposition may help us differentiate entity, such as that \"by\" is more likely to be followed by a person than a location. In general, the token itself plays the most important role in our MaxEnt Classifier according to the classifier.show_most_informative_features function. \n",
    "\n",
    "However, different tokens and different context have different ranks on features. One example is provided below: This is the feature explanation for classifying \"Yale\" in sentence \"Yale University is a university. \"\n",
    "     \n",
    "         Feature                                            B-ORG       O   B-PER   I-ORG\n",
    "      --------------------------------------------------------------------------------\n",
    "      next_University==1 (1)                             3.193\n",
    "      pre_O==0 (1)                                      -2.826\n",
    "      text=='Yale' (1)                                   2.684\n",
    "      any_cap==1 (1)                                     0.908\n",
    "      sentence_initial==1 (1)                            0.855\n",
    "      pos_is_NNP==1 (1)                                  0.801\n",
    "      pre_the==0 (1)                                    -0.599\n",
    "    \n",
    "\n",
    "  \n",
    "And the most important feature to choose the right lable B-ORG is next_University==1.\n",
    "\n",
    "However, the word \"Cornell\" in sentence \"Cornell University in located in Ithaca\" was assigned the incorrect label \"B-PER\". \n",
    "\n",
    "        Feature                                          B-PER      O   B-ORG    I-ORG\n",
    "      --------------------------------------------------------------------------------\n",
    "      text=='Cornell' (1)                                3.407\n",
    "      pre_O==0 (1)                                      -1.834\n",
    "      sentence_initial==1 (1)                            0.884\n",
    "      any_cap==1 (1)                                     0.829\n",
    "      pos_is_NNP==1 (1)                                  0.790\n",
    "\n",
    "\n",
    "\n",
    "In this case, the most importatn feature is different -- it is the text=='Cornell' feature. Since Cornell can be a person name or a university name, it is ambiguous. It seems like the pre_O==0 feature prevented the classifier to choose \"B_ORG\" to be the lable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>MISC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.542222</td>\n",
       "      <td>0.351515</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>0.557292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.922414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.664850</td>\n",
       "      <td>0.487395</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.694805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LOC      MISC       ORG       PER\n",
       "Recall     0.542222  0.351515  0.357895  0.557292\n",
       "Precision  0.859155  0.794521  0.829268  0.922414\n",
       "F1         0.664850  0.487395  0.500000  0.694805"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.DataFrame.from_dict(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall F1 score of MEMM is 0.5060. According the previous table, we can see different types of tags have different recall, precision and F1 scores. \n",
    "\n",
    "The recall is #Correct NEs / # Predicted NEs, the precision is #Correct NEs / #NEs in answer key, and the F-Measure(F1) is 2PR / (P+R). In our model, this table shows that the PER tags have the best performance, with the highest F1 score of 0.695, the recall of 0.557, the precision of 0.922. According to the definition of recall, there are about 55.7% of the true PER tags are correctly recognized. The LOC tag recognition have relatively good performance. Then is the performance of recognizing ORG tags. The MISC tags have the worst performance, with the lowest F1 score of 0.487, the recall of 0.351 and the precision of 0.794. The result depicted that this system works better when recognizing person's names and locations, but it fails when recognizing organization names and miscellaneous entities. This is very similar to the HMM result. In the MEMM model, these relatively large errors happens in MISC and ORG tags probably also because these entities have more complicated rules than PER and LOC tags. Also, it is probably because we didn't choose appropriate features targeting at these types of tags. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.explain(test_feature_extract('Yale', 'NNP', next_word = 'University'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.explain(test_feature_extract('Cornell', 'NNP', next_word = 'University'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4XaDMlcaDBA"
   },
   "source": [
    "<a name=\"q3.4\"></a>\n",
    "[[^^^]](#outline) \n",
    "\n",
    "## **Q3.4: Room for Improvement**\n",
    "When did the system work well, when did it fail and any ideas as to why? How might you improve the system? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_esMp_pOeGD"
   },
   "source": [
    "#### **A3.4:**\n",
    "\n",
    "Adding more features not always works. Sometimes it make the system fails and get worse performace score.<br>\n",
    "We think the manual feature selection is the most important part to improve the system. Even if we inspect the previous tag and previous special words, we still don't include enough meaningful context information. The model cannot learn much from the existing context. However, recording every word as a feature is costly. To save time and energy, we think that isn't a good way to improve. In the future, maybe there are some ways to include the context information more and cost less. Also, we only inspect some part of the training data, and we decided to add features like \"pre_at\",\"pre_of\",\"pre_University\" and so on. There should be some other rules that we didn't notice. By inspecting the document and adding more meaningful word lists like prefixs, suffixs, or alias, the system may be improved. <br> \n",
    "\n",
    "In addition, the overfitting problem is very obvious, since in each iteration of the MEMM training, the accuracy always increases and get to nearly 100% accurate. That will lead to the overfitting of training data and cause large variation on validation and test data. In our training features, there should be some useless ones that leads to the overfitting. We need to remove these features to improve the system. <br>\n",
    "\n",
    "**Moreover, when generating feature vectors, we realized that we made a mistake. We set each feature originally to 0, but some of the words may not have some of the features. For example, if a word is in the middle of the sentence, the 'sentence_initial' should not have a value. There is significant difference between a \"null\" value and a \"0\" value. Also, the feature vector of each word doesn't have to have the same dimensions. Fixing this may lead to a large improvement of the model, both in the running-time and the performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQwPwqU3vMiS"
   },
   "source": [
    "<a name=\"part4\"></a>\n",
    "# **Part 4: Comparing HMMs and MEMMs**\n",
    "[[^^^]](#outline) \n",
    "\n",
    "---\n",
    "\n",
    "In this section you will be asked to analyze and compare the models you have developed!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndVxVFzFagZ5"
   },
   "source": [
    "<a name=\"q4.1\"></a>\n",
    "[[^^^]](#outline) \n",
    "\n",
    "## **Q4.1: Result Comparison**\n",
    "Compare here your results (validation scores) for your HMM and the MEMM. Which of them performs better? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuXjldBAOgXf"
   },
   "source": [
    "#### **A4.1:**\n",
    "\n",
    "HMM: f1 = 0.5058 </br>\n",
    "MEMM: f1 = 0.5060 (after 100 iteration)\n",
    "\n",
    "HMM and MEMM have similar performance. This is actually not expected by us when we implemented two algorithm. Since MEMM contains more information (features) then HMM does, we expected MEMM should learn more and behave better than HMM which only contains transition and emission probability. Even though we experimented with many different feature sets for MEMM, we still cannot get a very good performance. One thing needs to be noted is that the best f1 score for MEMM was after 100 iteration which is extremely time-consuming while HMM did not take very long time to be trained. \n",
    "\n",
    "One reason is that our feature selection may not be good enough. We found that adding more features sometime decreases the accuracy of model performance. It is possible that we added some features that are not important to learn the labels or even further confuse the models. \n",
    "\n",
    "Another reason is the overfitting issue. In the training phase, we got accuracy around 0.980, but the F1 score on validation data is not as good. Since we were choosing our own features based on the training dataset which describe the training data very well but not necessay can capture the test data, it is very easy to get overfitting issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>MISC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.524444</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.836879</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.644809</td>\n",
       "      <td>0.474308</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.699029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LOC      MISC       ORG       PER\n",
       "Recall     0.524444  0.363636  0.368421  0.562500\n",
       "Precision  0.836879  0.681818  0.636364  0.923077\n",
       "F1         0.644809  0.474308  0.466667  0.699029"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HMM\n",
    "pd.DataFrame.from_dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>MISC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.542222</td>\n",
       "      <td>0.351515</td>\n",
       "      <td>0.357895</td>\n",
       "      <td>0.557292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.922414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.664850</td>\n",
       "      <td>0.487395</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.694805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LOC      MISC       ORG       PER\n",
       "Recall     0.542222  0.351515  0.357895  0.557292\n",
       "Precision  0.859155  0.794521  0.829268  0.922414\n",
       "F1         0.664850  0.487395  0.500000  0.694805"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEMM\n",
    "pd.DataFrame.from_dict(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjGcdm5aafl3"
   },
   "source": [
    "<a name=\"q4.2\"></a>\n",
    "[[^^^]](#outline) \n",
    "\n",
    "## **Q4.2: Error Analysis 1**\n",
    "Do some error analysis. What are error patterns you observed that the HMM makes but the MEMM does not? Try to justify why/why not? **Please give examples from the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "['<unk>', '<unk>', 'gas', 'for', 'creamy', '<unk>', 'is', 'usually', '75', '%', 'nitrogen', 'and', '25', '%', '<unk>', 'This', '<unk>', 'gas', 'which', 'only', 'works', 'well', 'with', 'creamy', '<unk>', 'is', 'often', 'referred', 'to', 'as', '<unk>', '<unk>', ',', '<unk>', '<unk>', ',', 'or', '<unk>', '(', 'an', 'Air', '<unk>', 'brand', 'name', ')', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<end>']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-MISC', 'I-MISC', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'I-MISC', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O']\n",
      "HMM ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "MEMM ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER']\n",
      "106\n",
      "['Music', 'written', 'using', 'the', 'modes', '<unk>', 'conventional', '<unk>', 'harmonic', '<unk>', ',', 'since', 'for', 'example', 'Messiaen', \"'s\", '<unk>', '2', '(', 'identical', 'to', 'the', '\"', '<unk>', 'scale', '\"', 'used', 'also', 'by', 'other', 'composers', ')', 'permits', '<unk>', 'the', 'dominant', 'seventh', '<unk>', 'whose', '<unk>', 'the', 'mode', 'does', 'not', 'contain', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<end>']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "HMM ['B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "MEMM ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER']\n",
      "210\n",
      "['<unk>', '<unk>', 'returns', 'from', 'the', 'woods', ',', 'he', 'sees', 'what', 'has', 'happened', 'and', 'acts', 'quickly', 'by', 'putting', 'their', '<unk>', 'inside', 'his', '<unk>', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<end>']\n",
      "['O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "HMM ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "MEMM ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER']\n",
      "302\n",
      "['The', 'Jerusalem', 'campus', 'is', 'the', 'only', '<unk>', 'in', 'Israel', 'for', 'training', '<unk>', 'Jewish', 'clergy', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<end>']\n",
      "['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-MISC', 'B-MISC', 'O', 'O']\n",
      "HMM ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "MEMM ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'I-PER']\n"
     ]
    }
   ],
   "source": [
    "# Check the error that HMM makes but the MEMM does not\n",
    "for i in range(len(val['text'])):\n",
    "    o1 = val['text'][i]\n",
    "    a = val['NER'][i]\n",
    "    h = viterbi(hmm, o1)\n",
    "    M = MEMM(ME, o1)\n",
    "    \n",
    "    yes = False\n",
    "    \n",
    "    for j in range(len(a)):\n",
    "        if (M[j] == a[j]) and (h[j]!=a[j]):\n",
    "            yes = True\n",
    "            break\n",
    "        break\n",
    "    \n",
    "    if yes:\n",
    "        print(i)\n",
    "        print(val['text'][i])\n",
    "        print(a)\n",
    "        print(\"HMM\", h)\n",
    "        print(\"MEMM\", M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzFPgH9MOiQw"
   },
   "source": [
    "#### **A4.2:**\n",
    "\n",
    "By analyzing the errors, we found that HMM tends to make mistake at sentence-initial position -- it assigns an NER label to sentence-initial token which should be an \"O\", while MEMM does not make this kind of mistake. Some exmaples are: \n",
    "\n",
    "    1. ['Music', 'written', 'using', 'the', 'modes', ...]\n",
    "    Actual Labels: ['O', 'O', 'O', 'O', 'O', ...]\n",
    "    HMM Prediction: ['B-MISC', 'O', 'O', 'O', 'O',...]\n",
    "    MEMM Prediction: ['O', 'O', 'O', 'O', 'O',...]\n",
    "    \n",
    "    2. ['The', 'Jerusalem', 'campus', 'is', 'the', 'only', ...]\n",
    "    Actual Labels: ['O', 'B-LOC', 'O', 'O', 'O', 'O', ...]\n",
    "    HMM Prediction: ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', ...]\n",
    "    MEMM Prediction: ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', ...]\n",
    "\n",
    "    \n",
    "We think it is because in MEMM we have two features \"any_cap\" and \"sentence_initial\". The MEMM learned that all sentence_initial token will have capitalization, thus the capitaliztion cannot provide many information on named entity at sentence-initial position and the MEMM model will use other feature to determine if it is an valid entity. However, HMM only has capitalization information stored as its lexical information. It only knows that if the word is captalized, it is more likely to be named entity. HMM does not learn about the position. \n",
    "\n",
    "Also, according to the error analysis in A4.1, the MEMM has better performace (F1 score 0.50) in recognizing ORG entities than HMM (F1 score 0.46). It is probably we include some other information that HMM cannot include such as part of speech and capitalization. These are features that related to the ORG entities and can help recognizing them correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZYfZAgga9UB"
   },
   "source": [
    "<a name=\"q4.3\"></a>\n",
    "[[^^^]](#outline) \n",
    "\n",
    "## **Q4.3: Error Analysis 2**\n",
    "What are error patterns you observed that MEMM makes but the HMM does not? Try to justify what you observe? **Please give examples from the dataset.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "['<unk>', 'Anderson', ',', '<unk>', 'Hart', ',', 'and', 'Ava', '<unk>', 'used', 'the', 'show', 'as', 'a', '<unk>', 'to', 'launch', 'their', 'own', 'successful', 'careers', 'as', 'country', 'music', 'solo', 'artists', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<end>']\n",
      "['B-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "HMM ['B-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "MEMM ['O', 'B-LOC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "209\n",
      "['Athens', 'fell', 'in', 'March', '<unk>', ',', 'and', 'the', 'city', 'was', 'sacked', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<end>']\n",
      "['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "HMM ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "MEMM ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "328\n",
      "['Chicago', 'remained', 'his', 'home', 'until', '1932', ',', 'when', 'he', 'settled', 'in', 'New', 'York', 'City', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<end>']\n",
      "['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
      "HMM ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "MEMM ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "397\n",
      "['<unk>', '<unk>', '(', '2007', ')', 'calls', 'the', '<unk>', 'question', '\"', '<unk>', '\"', ',', 'and', '<unk>', 'that', 'the', 'first', 'voyage', 'was', 'probably', 'another', 'version', 'of', 'the', 'second', ';', 'the', 'third', 'is', '<unk>', ',', 'and', 'the', 'fourth', 'is', 'probably', 'true', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<end>']\n",
      "['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "HMM ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n",
      "MEMM ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC']\n"
     ]
    }
   ],
   "source": [
    "# Check the error that HMM makes but the MEMM does not\n",
    "for i in range(len(val['text'])):\n",
    "    o1 = val['text'][i]\n",
    "    a = val['NER'][i]\n",
    "    h = viterbi(hmm, o1)\n",
    "    M = MEMM(ME, o1)\n",
    "    \n",
    "    yes = False\n",
    "    \n",
    "    for j in range(len(a)):\n",
    "        if (h[j] == a[j]) and (M[j]!=a[j]) and (a[j] != 'O'):\n",
    "            yes = True\n",
    "            break\n",
    "        break\n",
    "    \n",
    "    if yes:\n",
    "        print(i)\n",
    "        print(val['text'][i])\n",
    "        print(a)\n",
    "        print(\"HMM\", h)\n",
    "        print(\"MEMM\", M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Shm8ZaaoOjbg"
   },
   "source": [
    "#### **A4.3:**\n",
    "\n",
    "The most obvious pattern we observed is that MEMM cannot precisely tell the difference between PER tags and ORG tags. For example, in the sentence \n",
    "\n",
    "    \"Cornell University is located in Ithaca and was founded by Ezra Cornell.\",\n",
    "    HMM: ['B-ORG','I-ORG','O','O','O','B-LOC','O','O','O','O','B-PER','I-PER','O']\n",
    "    MEMM: ['B-PER','I-PER','O','O','O','B-LOC','O','O','O','O','B-PER','I-PER','O']\n",
    "    \n",
    "MEMM model sometimes mixed up Cornell University and Ezra Cornell. However, HMM can tell the difference between these two \"Cornell\". The reason is probably because we don't include much context information since we manually pick the features. In HMM, the model learn the context by itself. Especially \"Cornell\" as the last name seldom occur in the sentence initial position and usually follow the first name \"Ezra\". Person and Organization names sometimes appear in different positions in the sentences or may connected to some special words and influenced by its part of speech.\n",
    "\n",
    "It seems like the MEMM is able to detect the span of the entity, but sometimes get the label wrong. Another example is\n",
    "    \n",
    "    ['Chicago', 'remained', 'his', 'home', 'until', '1932',..]\n",
    "    HMM: ['B-LOC', 'O', 'O', 'O', 'O', 'O',...]\n",
    "    MEMM: ['B-ORG', 'O', 'O', 'O', 'O', 'O', ...]\n",
    "    \n",
    "Looking at the feature weight in the MEMM classifier, our analysis is that other features interact with \"is_loc\" which was suppose to be the most important feature. \n",
    "\n",
    "     Feature                                            B-ORG   B-LOC   B-PER   I-ORG\n",
    "      --------------------------------------------------------------------------------\n",
    "      pre_O==0 (1)                                      -2.826\n",
    "      text=='Chicago' (1)                                2.819\n",
    "      any_cap==1 (1)                                     0.908\n",
    "      sentence_initial==1 (1)                            0.855\n",
    "      pos_is_NNP==1 (1)                                  0.801\n",
    "      is_loc==1 (1)                                      0.725\n",
    "\n",
    "The most important feature became \"pre_O==0\". For future improvement, we should reconsider those features. And it is possible for \"Chicago\" to be used in other organization name, we need to find a way to tell the difference between \"Chicago\" as part of ORG name and \"Chicago\" as the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier.explain(test_feature_extract('Chicago', 'NNP', next_word = 'remained'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpugxBD7RBy1"
   },
   "source": [
    "<a name=\"part5\"></a>\n",
    "# **Part 5: Kaggle Submission**\n",
    "[[^^^]](#outline) \n",
    "\n",
    "---\n",
    "\n",
    "Using the best-performing system from among all of your HMM and MEMM models, generate predictions for the test set, and submit them to [Kaggle competition](https://www.kaggle.com/t/200697e4726f448986930dd4e823e957). Below, we provide a function that submits given predicted tokens and associated token indices in the correct format. As a scoring metric on Kaggle, we use **Entity Level Mean F1**.\n",
    "\n",
    "Your submission to Kaggle should be a CSV file consisting of five lines and two columns. The first line is a fixed header, and each of the remaining four lines corresponds to one of the four types of named entities. The first column is the label identifier *Id* (one of PER, LOC, ORG or MISC), and the second column *Predicted* is a list of entities (separated by single space) that you predict to be of that type. Each entity is specified by its starting and ending index (concatenated by a hypen) as given in the test corpus. \n",
    "\n",
    "You can use the function **create_submission** that takes the list of predicted labels and the list of associated token indices as inputs and creates the the output CSV file at a specified path.\n",
    "\n",
    "NOTE: Ensure that there are **no** rows with *Id* = \"O\" in your Kaggle Submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "893l9j77ETFM"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def create_submission(output_filepath, token_labels, token_inds):\n",
    "    \"\"\"\n",
    "    :parameter output_filepath: The full path (including file name) of the output file, \n",
    "                                with extension .csv\n",
    "    :type output_filepath: [String]\n",
    "    :parameter token_labels: A list of token labels (eg. PER, LOC, ORG or MISC).\n",
    "    :type token_labels: List[String]\n",
    "    :parameter token_indices: A list of token indices (taken from the dataset) \n",
    "                              corresponding to the labels in [token_labels].\n",
    "    :type token_indices: List[int]\n",
    "    \"\"\"\n",
    "    label_dict = format_output_labels(token_labels, token_inds)\n",
    "    with open(output_filepath, mode='w') as csv_file:\n",
    "        fieldnames = ['Id', 'Predicted']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for key in label_dict:\n",
    "            p_string = \" \".join([str(start)+\"-\"+str(end) for start,end in label_dict[key]])\n",
    "            writer.writerow({'Id': key, 'Predicted': p_string})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# TODO: please change the line below with your drive organization\n",
    "path = os.path.join(os.getcwd(),\"cs-4740-fa22-hw1-named-entity-recognition\")\n",
    "\n",
    "with open(os.path.join(path,'train.json'), 'r') as f:\n",
    "     train = json.loads(f.read())\n",
    "\n",
    "with open(os.path.join(path,'val.json'), 'r') as f:\n",
    "     val = json.loads(f.read())\n",
    "\n",
    "with open(os.path.join(path,'test.json'), 'r') as f:\n",
    "     test = json.loads(f.read())\n",
    "        \n",
    "token_inds = [item for subindex in test['index'] for item in subindex]\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(test['text'])):\n",
    "    prediction = MEMM(ME,test['text'][i])\n",
    "    predictions.append(prediction)\n",
    "predictions = [item for sub in predictions for item in sub]\n",
    "\n",
    "print(len(predictions) == len(token_inds))\n",
    "\n",
    "\n",
    "path = os.path.join(os.getcwd(), \"NLP4740_HW1_MEMM_try4.csv\")\n",
    "create_submission(path, predictions, token_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1lNil41VqMn"
   },
   "source": [
    "## **Baselines**\n",
    "\n",
    "On Kaggle, we provide two baselines for you to evaluate your models agaist: **`HMM Baseline`** and **`MEMM Baseline`**. You may use them to internally check your models. In addition, you would be getting points if for the final submission your best-performing model does better than the **`MEMM baseline`**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEZP_FGivVRI"
   },
   "source": [
    "---\n",
    "<a name=\"q5\"></a>\n",
    "## **Q5: Competition Score**\n",
    "[[^^^]](#outline) \n",
    "\n",
    "\n",
    "Include your **team name** and your **best score** from Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYirLL5x1mE7"
   },
   "source": [
    "#### **A5:**\n",
    "\n",
    "**team name:** B-PER </br>\n",
    "**best score for HMM:** 0.53395 </br>\n",
    "**best score for MEMM:** 0.50956 </br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
